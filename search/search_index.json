{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Hydrometerology Lab Computing Documentation","text":"<p>Welcome to the Hydrometerology Lab computing infrastructure documentation. This guide will help you get started with our computing resources and learn how to effectively use them for your research.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#for-new-users","title":"For New Users","text":"<p>If you're new to the lab, start here:</p> <ol> <li>Welcome &amp; Introduction - Learn about our infrastructure</li> <li>Getting Your Account - Set up your lab account</li> <li>SSH &amp; Remote Access - Connect to lab servers</li> <li>Using VSCode - Set up your development environment</li> </ol>"},{"location":"#common-tasks","title":"Common Tasks","text":"<ul> <li>Need to run a quick experiment? Check out Simple GPU Servers</li> <li>Processing large datasets? See CPU-Intensive Server</li> <li>Running jobs on HPC? Start with Preparing for Taiwan HPC</li> <li>Looking for specific commands? Visit the Quick Reference</li> </ul>"},{"location":"#for-maintainers","title":"For Maintainers","text":"<p>System administration and infrastructure documentation can be found in the Maintainer Documentation section.</p>"},{"location":"#infrastructure-overview","title":"Infrastructure Overview","text":"<p>Our lab maintains several computing servers and storage systems:</p> <ul> <li>Core Server: Central authentication and services (LDAP, Harbor Registry, MQTT, etc.)</li> <li>NAS Storage: 80TB for data and home directories</li> <li>GPU Servers: Three servers with NVIDIA GPUs for deep learning and computation</li> <li>Threadripper Server: High-core-count CPU server for data processing</li> <li>Taiwan HPC Access: For large-scale computational tasks</li> </ul>"},{"location":"#getting-help","title":"Getting Help","text":"<p>If you encounter issues or have questions:</p> <ul> <li>Check the FAQ for common problems</li> <li>Contact the lab system administrator</li> <li>Ask senior lab members</li> </ul> <p>Ready to get started? Head to Welcome &amp; Introduction to begin!</p>"},{"location":"basic-usage/data-storage/","title":"Data Storage &amp; Organization","text":""},{"location":"basic-usage/data-storage/#overview","title":"Overview","text":"<p>Understanding our storage structure is crucial for efficient work and collaboration in the lab.</p>"},{"location":"basic-usage/data-storage/#nas-structure","title":"NAS Structure","text":""},{"location":"basic-usage/data-storage/#data-shared-datasets","title":"<code>/data</code> - Shared Datasets","text":"<p>This directory contains shared datasets that everyone in the lab can access:</p> <pre><code>/data/\n\u251c\u2500\u2500 ERA5/           # ERA5 reanalysis data\n\u251c\u2500\u2500 IMERG/          # GPM IMERG precipitation data\n\u251c\u2500\u2500 radar/          # Weather radar data\n\u251c\u2500\u2500 satellite/      # Satellite observations\n\u251c\u2500\u2500 gauge/          # Rain gauge measurements\n\u2514\u2500\u2500 [other datasets]\n</code></pre> <p>Characteristics: - Read-only for most users (or write-protected) - Organized by data source - [Content to be added: Access permissions, update frequency]</p> <p>Best Practices: - Don't copy large datasets to your home directory - Reference data directly from <code>/data</code> in your scripts - [Content to be added: More guidelines]</p>"},{"location":"basic-usage/data-storage/#homes-user-directories","title":"<code>/homes</code> - User Directories","text":"<p>Each user has a home directory on the NAS:</p> <pre><code>/nas/homes/your-username/\n</code></pre> <p>Characteristics: - Your personal space on the NAS - Shared across all computing servers - [Content to be added: Quota information] - [Content to be added: Backup policy]</p>"},{"location":"basic-usage/data-storage/#local-home-directories","title":"Local Home Directories","text":"<p>Each computing server also has a local home directory:</p> <pre><code>/home/your-username/\n</code></pre> <p>Characteristics: - Faster access (local SSD) - Not shared between servers - [Content to be added: Backup policy]</p>"},{"location":"basic-usage/data-storage/#where-to-store-what","title":"Where to Store What?","text":"Data Type Location Reason Raw datasets (ERA5, IMERG, etc.) <code>/data</code> Shared, no duplication Your analysis scripts NAS home Accessible from all servers Your processed results NAS home Long-term storage Temporary processing files Local home Faster I/O Active code being developed Either Your preference Large intermediate files Local home Faster, but clean up when done"},{"location":"basic-usage/data-storage/#best-practices","title":"Best Practices","text":""},{"location":"basic-usage/data-storage/#1-dont-duplicate-large-datasets","title":"1. Don't Duplicate Large Datasets","text":"<p>\u274c Don't do this: <pre><code>cp -r /data/ERA5/2023/ ~/my_analysis/\n</code></pre></p> <p>\u2705 Do this instead: <pre><code># In your analysis script\ndata_path = '/data/ERA5/2023/'\n</code></pre></p>"},{"location":"basic-usage/data-storage/#2-organize-your-projects","title":"2. Organize Your Projects","text":"<p>[Content to be added: Suggested directory structure for research projects]</p>"},{"location":"basic-usage/data-storage/#3-clean-up-temporary-files","title":"3. Clean Up Temporary Files","text":"<p>[Content to be added: Importance of cleaning up, disk quota]</p>"},{"location":"basic-usage/data-storage/#4-use-symbolic-links","title":"4. Use Symbolic Links","text":"<p>[Content to be added: How to use symlinks to reference data]</p>"},{"location":"basic-usage/data-storage/#checking-your-disk-usage","title":"Checking Your Disk Usage","text":"<pre><code># Check your NAS home usage\ndu -sh /nas/homes/your-username\n\n# Check your local home usage\ndu -sh ~\n\n# See what's taking up space\ndu -h --max-depth=1 ~ | sort -h\n</code></pre>"},{"location":"basic-usage/data-storage/#data-transfer","title":"Data Transfer","text":""},{"location":"basic-usage/data-storage/#between-your-computer-and-servers","title":"Between Your Computer and Servers","text":"<p>[Content to be added: Using scp, rsync, or VSCode]</p>"},{"location":"basic-usage/data-storage/#between-servers","title":"Between Servers","text":"<p>[Content to be added: Since NAS home is shared, files are automatically available]</p>"},{"location":"basic-usage/data-storage/#future-dedicated-data-nas","title":"Future: Dedicated Data NAS","text":"<p>[Content to be added: Plans for 18-bay NAS to become primary data storage]</p> <p>Next Step: Learn about Simple GPU Servers</p>"},{"location":"basic-usage/linux-basics/","title":"Linux Command Line Basics","text":""},{"location":"basic-usage/linux-basics/#introduction","title":"Introduction","text":"<p>This page covers essential Linux commands you'll use daily in the lab. Don't worry about memorizing everything - you'll learn through practice!</p>"},{"location":"basic-usage/linux-basics/#file-system-navigation","title":"File System Navigation","text":""},{"location":"basic-usage/linux-basics/#pwd-print-working-directory","title":"pwd - Print Working Directory","text":"<pre><code>pwd\n</code></pre> <p>Shows your current location in the file system.</p>"},{"location":"basic-usage/linux-basics/#ls-list-files","title":"ls - List Files","text":"<pre><code>ls                  # List files in current directory\nls -l              # Long format with details\nls -lh             # Human-readable file sizes\nls -a              # Show hidden files (starting with .)\nls /path/to/dir    # List specific directory\n</code></pre>"},{"location":"basic-usage/linux-basics/#cd-change-directory","title":"cd - Change Directory","text":"<pre><code>cd /path/to/directory    # Go to specific directory\ncd ..                    # Go up one level\ncd ~                     # Go to your home directory\ncd -                     # Go to previous directory\n</code></pre>"},{"location":"basic-usage/linux-basics/#file-operations","title":"File Operations","text":""},{"location":"basic-usage/linux-basics/#creating-files-and-directories","title":"Creating Files and Directories","text":"<pre><code>mkdir directory_name        # Create a directory\nmkdir -p path/to/nested/dir # Create nested directories\ntouch filename.txt          # Create empty file\n</code></pre>"},{"location":"basic-usage/linux-basics/#copying-moving-and-deleting","title":"Copying, Moving, and Deleting","text":"<pre><code>cp source.txt destination.txt           # Copy file\ncp -r source_dir/ destination_dir/     # Copy directory\nmv oldname.txt newname.txt              # Rename/move file\nrm file.txt                             # Delete file\nrm -r directory/                        # Delete directory\n</code></pre> <p>Danger</p> <p>Be careful with <code>rm</code> - there's no recycle bin! Deleted files are gone forever.</p>"},{"location":"basic-usage/linux-basics/#viewing-files","title":"Viewing Files","text":"<pre><code>cat file.txt              # Display entire file\nless file.txt             # View file page by page (q to quit)\nhead file.txt             # Show first 10 lines\nhead -n 20 file.txt       # Show first 20 lines\ntail file.txt             # Show last 10 lines\ntail -f logfile.txt       # Follow file (useful for logs)\n</code></pre>"},{"location":"basic-usage/linux-basics/#file-permissions","title":"File Permissions","text":"<p>[Content to be added: Understanding rwx permissions, chmod basics]</p>"},{"location":"basic-usage/linux-basics/#searching-and-finding","title":"Searching and Finding","text":""},{"location":"basic-usage/linux-basics/#grep-search-in-files","title":"grep - Search in Files","text":"<pre><code>grep \"search_term\" file.txt\ngrep -r \"search_term\" directory/    # Recursive search\ngrep -i \"search_term\" file.txt      # Case-insensitive\n</code></pre>"},{"location":"basic-usage/linux-basics/#find-find-files","title":"find - Find Files","text":"<pre><code>find . -name \"filename.txt\"\nfind . -name \"*.py\"                 # Find all Python files\nfind . -type d -name \"data\"         # Find directories named \"data\"\n</code></pre>"},{"location":"basic-usage/linux-basics/#working-with-your-two-homes","title":"Working with Your Two Homes","text":"<p>Remember, you have two home directories:</p> <pre><code># Your local home (fast, but not shared)\ncd ~\ncd /home/your-username\n\n# Your NAS home (shared across all servers)\ncd /nas/homes/your-username\n</code></pre>"},{"location":"basic-usage/linux-basics/#disk-usage","title":"Disk Usage","text":"<pre><code>df -h                    # Show disk space\ndu -sh directory/        # Show directory size\ndu -h --max-depth=1      # Show size of subdirectories\n</code></pre>"},{"location":"basic-usage/linux-basics/#process-management","title":"Process Management","text":"<pre><code>top                      # View running processes (q to quit)\nhtop                     # Better version of top (if installed)\nps aux | grep python     # Find Python processes\nkill PID                 # Stop a process\n</code></pre>"},{"location":"basic-usage/linux-basics/#system-information","title":"System Information","text":"<pre><code>hostname                 # Show server name\nwhoami                   # Show your username\nuptime                   # Show how long server has been running\n</code></pre>"},{"location":"basic-usage/linux-basics/#tips-for-beginners","title":"Tips for Beginners","text":""},{"location":"basic-usage/linux-basics/#tab-completion","title":"Tab Completion","text":"<p>Press <code>Tab</code> to auto-complete file names and commands. Press <code>Tab</code> twice to see all possibilities.</p>"},{"location":"basic-usage/linux-basics/#command-history","title":"Command History","text":"<ul> <li>Use <code>\u2191</code> and <code>\u2193</code> arrows to navigate previous commands</li> <li><code>Ctrl+R</code> to search command history</li> </ul>"},{"location":"basic-usage/linux-basics/#getting-help","title":"Getting Help","text":"<pre><code>man command              # Show manual for command\ncommand --help           # Show quick help\n</code></pre>"},{"location":"basic-usage/linux-basics/#quick-reference","title":"Quick Reference","text":"<p>[Content to be added: Cheat sheet table of most common commands]</p> <p>Next Step: Learn about Data Storage &amp; Organization</p>"},{"location":"basic-usage/ssh-setup/","title":"SSH &amp; Remote Access","text":""},{"location":"basic-usage/ssh-setup/#what-is-ssh","title":"What is SSH?","text":"<p>SSH (Secure Shell) is the standard way to securely connect to remote Linux servers. You'll use SSH to access all of our lab's computing resources.</p> <p>[Content to be added: Simple explanation of SSH]</p>"},{"location":"basic-usage/ssh-setup/#generating-ssh-keys","title":"Generating SSH Keys","text":"<p>SSH keys provide secure, password-less authentication to servers.</p>"},{"location":"basic-usage/ssh-setup/#on-windows","title":"On Windows","text":"<p>[Content to be added: Using PowerShell or WSL to generate keys]</p>"},{"location":"basic-usage/ssh-setup/#on-macoslinux","title":"On macOS/Linux","text":"<pre><code>ssh-keygen -t ed25519 -C \"your.email@example.com\"\n</code></pre> <p>[Content to be added: Full walkthrough with explanations]</p>"},{"location":"basic-usage/ssh-setup/#understanding-your-keys","title":"Understanding Your Keys","text":"<p>[Content to be added: Public vs private key, security best practices]</p>"},{"location":"basic-usage/ssh-setup/#uploading-your-public-key","title":"Uploading Your Public Key","text":"<p>Once you've generated your SSH key pair, you need to upload your public key to the LDAP Account Manager.</p>"},{"location":"basic-usage/ssh-setup/#steps","title":"Steps","text":"<ol> <li>[Content to be added: Log in to LDAP Account Manager]</li> <li>[Content to be added: Navigate to SSH keys section]</li> <li>[Content to be added: Paste your public key]</li> <li>[Content to be added: Save and verify]</li> </ol> <p>Warning</p> <p>Never share your private key! Only upload your public key (the <code>.pub</code> file).</p>"},{"location":"basic-usage/ssh-setup/#configuring-your-ssh-config-file","title":"Configuring Your SSH Config File","text":"<p>The SSH config file makes connecting to servers much easier by storing connection settings.</p>"},{"location":"basic-usage/ssh-setup/#location","title":"Location","text":"<ul> <li>Linux/macOS: <code>~/.ssh/config</code></li> <li>Windows: <code>C:\\Users\\YourUsername\\.ssh\\config</code></li> </ul>"},{"location":"basic-usage/ssh-setup/#example-configuration","title":"Example Configuration","text":"<pre><code># GPU Server 1 - i7 + 3080 Ti\nHost gpu1\n    HostName [IP or hostname]\n    User your-username\n    IdentityFile ~/.ssh/id_ed25519\n\n# GPU Server 2 - i9 + 4090\nHost gpu2\n    HostName [IP or hostname]\n    User your-username\n    IdentityFile ~/.ssh/id_ed25519\n\n# GPU Server 3 - 5950 + 3090\nHost gpu3\n    HostName [IP or hostname]\n    User your-username\n    IdentityFile ~/.ssh/id_ed25519\n\n# Threadripper - CPU Server\nHost threadripper\n    HostName [IP or hostname]\n    User your-username\n    IdentityFile ~/.ssh/id_ed25519\n</code></pre> <p>[Content to be added: More detailed explanation]</p>"},{"location":"basic-usage/ssh-setup/#connecting-to-servers","title":"Connecting to Servers","text":"<p>Once your SSH keys are uploaded and config is set up:</p> <pre><code>ssh gpu1\n</code></pre> <p>[Content to be added: Troubleshooting common issues]</p>"},{"location":"basic-usage/ssh-setup/#first-connection","title":"First Connection","text":"<p>[Content to be added: What to expect on first login, accepting host key]</p>"},{"location":"basic-usage/ssh-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"basic-usage/ssh-setup/#permission-denied-publickey","title":"Permission Denied (publickey)","text":"<p>[Content to be added: Common fixes]</p>"},{"location":"basic-usage/ssh-setup/#connection-timeout","title":"Connection Timeout","text":"<p>[Content to be added: Network issues, VPN requirements if any]</p>"},{"location":"basic-usage/ssh-setup/#host-key-verification-failed","title":"Host Key Verification Failed","text":"<p>[Content to be added: How to handle host key changes]</p> <p>Next Step: Set up VSCode for Remote Development</p>"},{"location":"basic-usage/vscode/","title":"Using VSCode for Remote Development","text":""},{"location":"basic-usage/vscode/#why-vscode","title":"Why VSCode?","text":"<p>Visual Studio Code (VSCode) with the Remote SSH extension provides an excellent development environment for working on remote servers. You can edit code, run terminals, and debug as if you were working locally.</p>"},{"location":"basic-usage/vscode/#prerequisites","title":"Prerequisites","text":"<ul> <li>VSCode installed on your local computer</li> <li>SSH keys configured (see SSH Setup)</li> <li>SSH config file set up</li> </ul>"},{"location":"basic-usage/vscode/#installing-the-remote-ssh-extension","title":"Installing the Remote-SSH Extension","text":"<p>[Content to be added: Step-by-step installation of Remote-SSH extension]</p>"},{"location":"basic-usage/vscode/#connecting-to-a-server","title":"Connecting to a Server","text":""},{"location":"basic-usage/vscode/#using-ssh-config","title":"Using SSH Config","text":"<p>[Content to be added: Using the hosts defined in SSH config]</p>"},{"location":"basic-usage/vscode/#first-connection","title":"First Connection","text":"<p>[Content to be added: What happens, accepting fingerprint]</p>"},{"location":"basic-usage/vscode/#working-in-vscode","title":"Working in VSCode","text":""},{"location":"basic-usage/vscode/#file-explorer","title":"File Explorer","text":"<p>[Content to be added: Navigating files on remote server]</p>"},{"location":"basic-usage/vscode/#integrated-terminal","title":"Integrated Terminal","text":"<p>[Content to be added: Using terminal in VSCode]</p>"},{"location":"basic-usage/vscode/#editing-files","title":"Editing Files","text":"<p>[Content to be added: Opening and editing remote files]</p>"},{"location":"basic-usage/vscode/#extensions-on-remote","title":"Extensions on Remote","text":"<p>[Content to be added: Installing extensions on the remote server]</p>"},{"location":"basic-usage/vscode/#recommended-extensions","title":"Recommended Extensions","text":"<p>[Content to be added: List of useful extensions for your work]</p> <ul> <li>Python</li> <li>Jupyter</li> <li>Docker</li> <li>[Add more based on your lab's needs]</li> </ul>"},{"location":"basic-usage/vscode/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"basic-usage/vscode/#multiple-terminals","title":"Multiple Terminals","text":"<p>[Content to be added]</p>"},{"location":"basic-usage/vscode/#split-editor","title":"Split Editor","text":"<p>[Content to be added]</p>"},{"location":"basic-usage/vscode/#port-forwarding","title":"Port Forwarding","text":"<p>[Content to be added: For Jupyter notebooks, TensorBoard, etc.]</p>"},{"location":"basic-usage/vscode/#troubleshooting","title":"Troubleshooting","text":"<p>[Content to be added: Common VSCode remote issues]</p> <p>Next Step: Learn Linux Command Line Basics</p>"},{"location":"computing/gpu-servers/","title":"Simple GPU Servers","text":""},{"location":"computing/gpu-servers/#overview","title":"Overview","text":"<p>The lab has three GPU servers that students can SSH into directly and install software as needed. These servers are ideal for interactive work, initial experiments, and moderate computation.</p>"},{"location":"computing/gpu-servers/#available-gpu-servers","title":"Available GPU Servers","text":""},{"location":"computing/gpu-servers/#server-1-i7-rtx-3080-ti","title":"Server 1: i7 + RTX 3080 Ti","text":"<p>Hostname: [To be added]</p> <p>Specifications: - CPU: Intel i7 - GPU: NVIDIA RTX 3080 Ti - RAM: [To be added]</p> <p>Best For: - Quick experiments and testing - Initial model development - Interactive debugging</p>"},{"location":"computing/gpu-servers/#server-2-i9-rtx-4090","title":"Server 2: i9 + RTX 4090","text":"<p>Hostname: [To be added]</p> <p>Specifications: - CPU: Intel i9 - GPU: NVIDIA RTX 4090 (most powerful GPU) - RAM: [To be added]</p> <p>Best For: - Heavy deep learning tasks - Large model training - GPU-intensive computations</p>"},{"location":"computing/gpu-servers/#server-3-5950-rtx-3090","title":"Server 3: 5950 + RTX 3090","text":"<p>Hostname: [To be added]</p> <p>Specifications: - CPU: AMD Ryzen 9 5950X - GPU: NVIDIA RTX 3090 - RAM: [To be added]</p> <p>Best For: - General GPU computing - Medium-scale experiments</p>"},{"location":"computing/gpu-servers/#connecting-to-gpu-servers","title":"Connecting to GPU Servers","text":"<p>Using your SSH config:</p> <pre><code>ssh gpu1  # or gpu2, gpu3\n</code></pre> <p>[Content to be added: First login, verifying you're on the right server]</p>"},{"location":"computing/gpu-servers/#key-features","title":"Key Features","text":""},{"location":"computing/gpu-servers/#sssd-authentication","title":"SSSD Authentication","text":"<p>All GPU servers use SSSD to communicate with the central LDAP server for authentication. This means: - Your username and password work on all servers - Your user account is consistent across all servers</p>"},{"location":"computing/gpu-servers/#nfs-mounted-nas","title":"NFS-Mounted NAS","text":"<p>Your NAS home directory is automatically mounted and available:</p> <pre><code>cd /nas/homes/your-username\n</code></pre>"},{"location":"computing/gpu-servers/#sudo-access","title":"Sudo Access","text":"<p>Unlike the Threadripper server, you have sudo access on these machines through a dedicated sudo account.</p> <p>[Content to be added: How to switch to sudo account and use it]</p>"},{"location":"computing/gpu-servers/#installing-software","title":"Installing Software","text":""},{"location":"computing/gpu-servers/#using-package-managers","title":"Using Package Managers","text":"<pre><code># Switch to sudo account\n[Content to be added: command to switch]\n\n# Install system packages\nsudo apt update\nsudo apt install package-name\n</code></pre>"},{"location":"computing/gpu-servers/#python-environments","title":"Python Environments","text":"<p>It's recommended to use virtual environments or conda:</p> <pre><code># Using venv\npython3 -m venv myenv\nsource myenv/bin/activate\npip install numpy pandas torch\n\n# Using conda (if installed)\nconda create -n myenv python=3.10\nconda activate myenv\nconda install pytorch torchvision -c pytorch\n</code></pre>"},{"location":"computing/gpu-servers/#cuda-and-gpu-libraries","title":"CUDA and GPU Libraries","text":"<p>[Content to be added: CUDA version installed, nvidia-smi usage]</p>"},{"location":"computing/gpu-servers/#checking-gpu-usage","title":"Checking GPU Usage","text":""},{"location":"computing/gpu-servers/#see-available-gpus","title":"See Available GPUs","text":"<pre><code>nvidia-smi\n</code></pre>"},{"location":"computing/gpu-servers/#monitor-gpu-usage-in-real-time","title":"Monitor GPU Usage in Real-Time","text":"<pre><code>watch -n 1 nvidia-smi\n</code></pre>"},{"location":"computing/gpu-servers/#check-whos-using-gpus","title":"Check Who's Using GPUs","text":"<pre><code>nvidia-smi\n# Look at the \"Processes\" section at the bottom\n</code></pre>"},{"location":"computing/gpu-servers/#best-practices","title":"Best Practices","text":""},{"location":"computing/gpu-servers/#1-check-before-using","title":"1. Check Before Using","text":"<p>Before starting a GPU-intensive task, check if someone else is using the GPU:</p> <pre><code>nvidia-smi\n</code></pre>"},{"location":"computing/gpu-servers/#2-be-considerate","title":"2. Be Considerate","text":"<p>[Content to be added: Resource sharing etiquette]</p>"},{"location":"computing/gpu-servers/#3-monitor-your-jobs","title":"3. Monitor Your Jobs","text":"<p>[Content to be added: Using tmux/screen for long-running jobs]</p>"},{"location":"computing/gpu-servers/#4-clean-up","title":"4. Clean Up","text":"<p>[Content to be added: Stopping processes, freeing GPU memory]</p>"},{"location":"computing/gpu-servers/#common-tasks","title":"Common Tasks","text":""},{"location":"computing/gpu-servers/#running-python-scripts","title":"Running Python Scripts","text":"<pre><code>python your_script.py\n</code></pre>"},{"location":"computing/gpu-servers/#using-jupyter-notebooks","title":"Using Jupyter Notebooks","text":"<p>[Content to be added: Setting up Jupyter on remote server, port forwarding]</p>"},{"location":"computing/gpu-servers/#using-tensorboard","title":"Using TensorBoard","text":"<p>[Content to be added: Port forwarding for TensorBoard]</p>"},{"location":"computing/gpu-servers/#when-to-use-hpc-instead","title":"When to Use HPC Instead","text":"<p>These GPU servers are great for interactive work and moderate tasks, but consider using Taiwan HPC when:</p> <ul> <li>Your job will run for days</li> <li>You need multiple GPUs</li> <li>You need guaranteed resources</li> <li>You're running production experiments</li> </ul> <p>See Preparing for Taiwan HPC for more information.</p> <p>Next Step: Learn about the CPU-Intensive Threadripper Server</p>"},{"location":"computing/threadripper/","title":"CPU-Intensive Server (Threadripper)","text":""},{"location":"computing/threadripper/#overview","title":"Overview","text":"<p>The Threadripper server is a high-core-count machine designed for CPU-intensive data processing tasks. It has a fundamentally different workflow from the GPU servers.</p> <p>Hostname: [To be added]</p>"},{"location":"computing/threadripper/#specifications","title":"Specifications","text":"<ul> <li>CPU: AMD Threadripper 7965 (24 cores, 48 threads)</li> <li>GPU: Basic GPU for display only (not for computation)</li> <li>RAM: [To be added]</li> </ul>"},{"location":"computing/threadripper/#key-differences-from-gpu-servers","title":"Key Differences from GPU Servers","text":""},{"location":"computing/threadripper/#no-sudo-access","title":"No Sudo Access","text":"<p>Unlike the GPU servers, you do not have sudo access on the Threadripper. This is intentional.</p>"},{"location":"computing/threadripper/#rootless-podman-workflow","title":"Rootless Podman Workflow","text":"<p>Instead of installing software directly, you use rootless Podman to run containers. This provides:</p> <ul> <li>Isolation between users</li> <li>Reproducibility</li> <li>No need for sudo on the host</li> <li>Easy migration to HPC</li> </ul> <p>Inside your containers, you do have sudo access, so you can install whatever you need.</p>"},{"location":"computing/threadripper/#why-this-approach","title":"Why This Approach?","text":"<p>[Content to be added: Benefits of containerized workflow]</p> <ol> <li>Reproducibility: Your environment is defined in a container</li> <li>Portability: Same container runs on HPC</li> <li>Isolation: Your work doesn't interfere with others</li> <li>Flexibility: Full control inside your container</li> </ol>"},{"location":"computing/threadripper/#getting-started-with-podman","title":"Getting Started with Podman","text":"<p>[Content to be added: This section will be covered in detail in the Containers section]</p> <p>For detailed Podman usage, see Using Podman on Threadripper.</p>"},{"location":"computing/threadripper/#when-to-use-threadripper","title":"When to Use Threadripper","text":""},{"location":"computing/threadripper/#good-use-cases","title":"Good Use Cases","text":"<ul> <li>Data preprocessing and cleaning</li> <li>Parallel processing of many files</li> <li>CPU-bound scientific computations</li> <li>Building and compiling code</li> <li>Tasks that need many CPU cores</li> </ul>"},{"location":"computing/threadripper/#not-ideal-for","title":"Not Ideal For","text":"<ul> <li>GPU-accelerated deep learning (use GPU servers)</li> <li>Interactive development (use GPU servers)</li> <li>Tasks requiring frequent system package installation (use GPU servers or containers)</li> </ul>"},{"location":"computing/threadripper/#quick-start-example","title":"Quick Start Example","text":"<p>[Content to be added: Simple example of pulling an image from Harbor and running it]</p> <pre><code># Pull a base image from our Harbor registry\npodman pull harbor.example.com/base/ubuntu:latest\n\n# Run an interactive container\npodman run -it --rm harbor.example.com/base/ubuntu:latest bash\n\n# Inside the container, you have sudo\nsudo apt update &amp;&amp; sudo apt install python3\n</code></pre>"},{"location":"computing/threadripper/#best-practices","title":"Best Practices","text":""},{"location":"computing/threadripper/#1-use-containers-from-harbor","title":"1. Use Containers from Harbor","text":"<p>[Content to be added: Why use internal registry]</p>"},{"location":"computing/threadripper/#2-mount-your-data","title":"2. Mount Your Data","text":"<p>[Content to be added: Using -v flag to mount directories]</p>"},{"location":"computing/threadripper/#3-long-running-jobs","title":"3. Long-Running Jobs","text":"<p>[Content to be added: Using podman in detached mode]</p>"},{"location":"computing/threadripper/#common-workflows","title":"Common Workflows","text":"<p>[Content to be added: Examples of typical data processing workflows]</p> <p>Next Step: Learn about Containers to understand how to effectively use Threadripper</p>"},{"location":"containers/building/","title":"Building Your Containers","text":""},{"location":"containers/building/#why-build-custom-containers","title":"Why Build Custom Containers?","text":"<p>While our base images are a good starting point, you'll often need to create custom containers with: - Specific software versions - Your own code - Custom dependencies - Reproducible research environments</p>"},{"location":"containers/building/#dockerfile-basics","title":"Dockerfile Basics","text":"<p>A Dockerfile is a text file with instructions for building a container image.</p>"},{"location":"containers/building/#simple-example","title":"Simple Example","text":"<pre><code># Start from a base image\nFROM harbor.example.com/base/python:latest\n\n# Set working directory\nWORKDIR /workspace\n\n# Install Python packages\nRUN pip install numpy pandas matplotlib\n\n# Copy your code\nCOPY my_script.py /workspace/\n\n# Set default command\nCMD [\"python\", \"my_script.py\"]\n</code></pre>"},{"location":"containers/building/#dockerfile-instructions","title":"Dockerfile Instructions","text":""},{"location":"containers/building/#from","title":"FROM","text":"<pre><code>FROM harbor.example.com/base/ubuntu:latest\n</code></pre> <p>Specifies the base image to start from.</p>"},{"location":"containers/building/#run","title":"RUN","text":"<pre><code>RUN apt update &amp;&amp; apt install -y python3\nRUN pip install numpy pandas\n</code></pre> <p>Executes commands during image build.</p>"},{"location":"containers/building/#copy","title":"COPY","text":"<pre><code>COPY local_file.txt /container/path/\nCOPY requirements.txt /workspace/\n</code></pre> <p>Copies files from your computer into the image.</p>"},{"location":"containers/building/#workdir","title":"WORKDIR","text":"<pre><code>WORKDIR /workspace\n</code></pre> <p>Sets the working directory for subsequent commands.</p>"},{"location":"containers/building/#env","title":"ENV","text":"<pre><code>ENV DATA_PATH=/data\nENV PYTHONUNBUFFERED=1\n</code></pre> <p>Sets environment variables.</p>"},{"location":"containers/building/#cmd","title":"CMD","text":"<pre><code>CMD [\"python\", \"script.py\"]\n</code></pre> <p>Default command when container starts.</p>"},{"location":"containers/building/#building-an-image","title":"Building an Image","text":"<pre><code># Build from Dockerfile in current directory\npodman build -t my-image:latest .\n\n# Build with specific Dockerfile\npodman build -f Dockerfile.custom -t my-image:latest .\n\n# Tag for Harbor\npodman tag my-image:latest harbor.example.com/your-project/my-image:latest\n</code></pre>"},{"location":"containers/building/#best-practices","title":"Best Practices","text":""},{"location":"containers/building/#1-start-from-our-base-images","title":"1. Start from Our Base Images","text":"<p>[Content to be added: Benefits of using lab base images]</p>"},{"location":"containers/building/#2-combine-run-commands","title":"2. Combine RUN Commands","text":"<p>\u274c Creates many layers: <pre><code>RUN apt update\nRUN apt install -y python3\nRUN apt install -y vim\n</code></pre></p> <p>\u2705 More efficient: <pre><code>RUN apt update &amp;&amp; apt install -y \\\n    python3 \\\n    vim \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre></p>"},{"location":"containers/building/#3-use-dockerignore","title":"3. Use .dockerignore","text":"<p>[Content to be added: Exclude unnecessary files from build]</p>"},{"location":"containers/building/#4-install-dependencies-first","title":"4. Install Dependencies First","text":"<pre><code># Copy and install dependencies first (cached layer)\nCOPY requirements.txt /workspace/\nRUN pip install -r requirements.txt\n\n# Copy code later (changes frequently)\nCOPY . /workspace/\n</code></pre>"},{"location":"containers/building/#example-research-project","title":"Example: Research Project","text":"<p>[Content to be added: Complete example Dockerfile for a typical research project]</p> <pre><code>FROM harbor.example.com/base/python-datascience:latest\n\n# Install additional packages\nRUN pip install xarray netCDF4 rasterio\n\n# Copy analysis code\nWORKDIR /workspace\nCOPY analysis/ /workspace/analysis/\nCOPY requirements.txt /workspace/\n\n# Install project-specific packages\nRUN pip install -r requirements.txt\n\n# Default command\nCMD [\"python\", \"analysis/main.py\"]\n</code></pre>"},{"location":"containers/building/#multi-stage-builds","title":"Multi-Stage Builds","text":"<p>[Content to be added: For more advanced users, building efficient images]</p>"},{"location":"containers/building/#testing-your-image","title":"Testing Your Image","text":"<pre><code># Build the image\npodman build -t my-image:latest .\n\n# Test it locally\npodman run -it --rm my-image:latest bash\n\n# Run your actual command\npodman run --rm \\\n  -v /data:/data:Z \\\n  -v /nas/homes/your-username:/workspace:Z \\\n  my-image:latest\n</code></pre>"},{"location":"containers/building/#pushing-to-harbor","title":"Pushing to Harbor","text":"<p>Once your image works:</p> <pre><code># Tag for Harbor\npodman tag my-image:latest harbor.example.com/your-project/my-image:v1.0\n\n# Push\npodman push harbor.example.com/your-project/my-image:v1.0\n</code></pre>"},{"location":"containers/building/#hpc-preparation","title":"HPC Preparation","text":"<p>[Content to be added: How to convert Podman images for HPC (Singularity/Apptainer)]</p> <p>The great thing about building containers is that the same image can run: 1. On your laptop (for testing) 2. On Threadripper (for medium-scale processing) 3. On Taiwan HPC (for large-scale production)</p> <p>Next Step: Learn about Preparing for Taiwan HPC</p>"},{"location":"containers/harbor/","title":"Harbor Registry","text":""},{"location":"containers/harbor/#what-is-harbor","title":"What is Harbor?","text":"<p>Harbor is our lab's private container registry. It's like Docker Hub, but: - Runs on our Core server - Only accessible to lab members - Contains curated base images for common tasks - Faster (local network)</p> <p>URL: [To be added]</p>"},{"location":"containers/harbor/#logging-in","title":"Logging In","text":""},{"location":"containers/harbor/#web-interface","title":"Web Interface","text":"<p>[Content to be added: How to access web UI, credentials]</p>"},{"location":"containers/harbor/#command-line","title":"Command Line","text":"<pre><code># Log in to Harbor\npodman login harbor.example.com\n\n# Enter your LDAP username and password\n</code></pre>"},{"location":"containers/harbor/#available-base-images","title":"Available Base Images","text":"<p>Our lab maintains several base images to make it easier to get started:</p>"},{"location":"containers/harbor/#baseubuntulatest","title":"<code>base/ubuntu:latest</code>","text":"<p>[Content to be added: Basic Ubuntu image]</p>"},{"location":"containers/harbor/#basepythonlatest","title":"<code>base/python:latest</code>","text":"<p>[Content to be added: Python with common scientific packages]</p>"},{"location":"containers/harbor/#basepython-datasciencelatest","title":"<code>base/python-datascience:latest</code>","text":"<p>[Content to be added: Full data science stack]</p>"},{"location":"containers/harbor/#basepytorchlatest","title":"<code>base/pytorch:latest</code>","text":"<p>[Content to be added: PyTorch for deep learning]</p>"},{"location":"containers/harbor/#basetensorflowlatest","title":"<code>base/tensorflow:latest</code>","text":"<p>[Content to be added: TensorFlow for deep learning]</p> <p>[Content to be added: More images as available]</p>"},{"location":"containers/harbor/#pulling-images","title":"Pulling Images","text":"<pre><code># Pull a base image\npodman pull harbor.example.com/library/ubuntu:latest\n\n# Use it\npodman run -it harbor.example.com/library/ubuntu:latest bash\n</code></pre>"},{"location":"containers/harbor/#creating-your-own-images","title":"Creating Your Own Images","text":"<p>You can create and push your own images to Harbor:</p>"},{"location":"containers/harbor/#build-an-image","title":"Build an Image","text":"<p>See Building Your Containers for details on creating images.</p>"},{"location":"containers/harbor/#push-to-harbor","title":"Push to Harbor","text":"<pre><code># Tag your image\npodman tag my-image:latest harbor.example.com/your-project/my-image:latest\n\n# Push to Harbor\npodman push harbor.example.com/your-project/my-image:latest\n</code></pre>"},{"location":"containers/harbor/#project-organization","title":"Project Organization","text":"<p>[Content to be added: How projects are organized in Harbor]</p>"},{"location":"containers/harbor/#image-tags","title":"Image Tags","text":"<p>[Content to be added: Versioning, latest vs specific versions]</p>"},{"location":"containers/harbor/#best-practices","title":"Best Practices","text":""},{"location":"containers/harbor/#1-use-specific-tags-for-reproducibility","title":"1. Use Specific Tags for Reproducibility","text":"<p>\u274c Don't rely on <code>latest</code>: <pre><code>podman pull harbor.example.com/base/python:latest\n</code></pre></p> <p>\u2705 Use specific versions: <pre><code>podman pull harbor.example.com/base/python:3.11-2024.1\n</code></pre></p>"},{"location":"containers/harbor/#2-document-your-images","title":"2. Document Your Images","text":"<p>[Content to be added: Including README in your projects]</p>"},{"location":"containers/harbor/#3-keep-images-small","title":"3. Keep Images Small","text":"<p>[Content to be added: Multi-stage builds, clean up in Dockerfile]</p>"},{"location":"containers/harbor/#harbor-web-interface","title":"Harbor Web Interface","text":""},{"location":"containers/harbor/#browsing-images","title":"Browsing Images","text":"<p>[Content to be added: How to explore available images]</p>"},{"location":"containers/harbor/#viewing-image-details","title":"Viewing Image Details","text":"<p>[Content to be added: Layers, size, tags]</p>"},{"location":"containers/harbor/#managing-your-images","title":"Managing Your Images","text":"<p>[Content to be added: Deleting old versions]</p> <p>Next Step: Learn about Building Your Containers</p>"},{"location":"containers/intro/","title":"Introduction to Containers","text":""},{"location":"containers/intro/#what-are-containers","title":"What Are Containers?","text":"<p>Containers are lightweight, portable packages that include your application and all its dependencies. Think of them as a complete computing environment that you can run anywhere.</p> <p>[Content to be added: Visual analogy, comparison to VMs]</p>"},{"location":"containers/intro/#why-containers-matter-for-research","title":"Why Containers Matter for Research","text":""},{"location":"containers/intro/#1-reproducibility","title":"1. Reproducibility","text":"<p>[Content to be added: Your exact environment can be recreated]</p>"},{"location":"containers/intro/#2-portability","title":"2. Portability","text":"<p>[Content to be added: Same container runs on lab servers and HPC]</p>"},{"location":"containers/intro/#3-dependency-management","title":"3. Dependency Management","text":"<p>[Content to be added: No more \"it works on my machine\"]</p>"},{"location":"containers/intro/#4-isolation","title":"4. Isolation","text":"<p>[Content to be added: Different projects with conflicting dependencies]</p>"},{"location":"containers/intro/#container-concepts","title":"Container Concepts","text":""},{"location":"containers/intro/#images","title":"Images","text":"<p>[Content to be added: Templates for containers]</p>"},{"location":"containers/intro/#containers","title":"Containers","text":"<p>[Content to be added: Running instances of images]</p>"},{"location":"containers/intro/#registries","title":"Registries","text":"<p>[Content to be added: Where images are stored (like GitHub for containers)]</p>"},{"location":"containers/intro/#docker-vs-podman","title":"Docker vs Podman","text":"<p>You'll hear both terms in this documentation. Here's what you need to know:</p>"},{"location":"containers/intro/#docker","title":"Docker","text":"<ul> <li>The original container platform</li> <li>Requires root/sudo access</li> <li>Most popular, lots of documentation online</li> <li>Many images on Docker Hub</li> </ul>"},{"location":"containers/intro/#podman","title":"Podman","text":"<ul> <li>Docker-compatible alternative</li> <li>Can run rootless (no sudo needed)</li> <li>Command syntax nearly identical to Docker</li> <li>What we use on Threadripper</li> </ul>"},{"location":"containers/intro/#key-point","title":"Key Point","text":"<p>If you find a Docker tutorial online, you can usually replace <code>docker</code> with <code>podman</code> and it will work!</p> <pre><code># Docker command\ndocker run -it ubuntu bash\n\n# Equivalent Podman command\npodman run -it ubuntu bash\n</code></pre>"},{"location":"containers/intro/#how-we-use-containers-in-the-lab","title":"How We Use Containers in the Lab","text":""},{"location":"containers/intro/#gpu-servers","title":"GPU Servers","text":"<p>On GPU servers, you have sudo access and can install software directly. Containers are optional but recommended for: - Testing before deploying to HPC - Reproducible research - Complex dependency management</p>"},{"location":"containers/intro/#threadripper","title":"Threadripper","text":"<p>On Threadripper, containers are required because you don't have sudo. But this is actually a good thing - it teaches good practices for HPC.</p>"},{"location":"containers/intro/#taiwan-hpc","title":"Taiwan HPC","text":"<p>[Content to be added: Most HPC systems support containers (Singularity/Apptainer)]</p>"},{"location":"containers/intro/#our-harbor-registry","title":"Our Harbor Registry","text":"<p>Instead of Docker Hub, we run our own private registry using Harbor:</p> <p>URL: [To be added]</p> <p>Benefits: - Faster (local network) - Private images for lab projects - Curated base images for common tasks</p> <p>Next Step: Learn about Using Podman on Threadripper</p>"},{"location":"containers/podman/","title":"Using Podman on Threadripper","text":""},{"location":"containers/podman/#introduction","title":"Introduction","text":"<p>This guide covers using rootless Podman on the Threadripper server for CPU-intensive tasks.</p>"},{"location":"containers/podman/#basic-podman-commands","title":"Basic Podman Commands","text":"<p>Podman commands are nearly identical to Docker. If you know Docker, you already know Podman!</p>"},{"location":"containers/podman/#pulling-images","title":"Pulling Images","text":"<pre><code># From our Harbor registry\npodman pull harbor.example.com/library/ubuntu:latest\n\n# From Docker Hub (if needed)\npodman pull docker.io/ubuntu:latest\n</code></pre>"},{"location":"containers/podman/#running-containers","title":"Running Containers","text":"<pre><code># Interactive container\npodman run -it ubuntu:latest bash\n\n# Run in background (detached)\npodman run -d ubuntu:latest sleep infinity\n\n# Run with a name\npodman run -it --name my-container ubuntu:latest bash\n</code></pre>"},{"location":"containers/podman/#listing-containers","title":"Listing Containers","text":"<pre><code># Show running containers\npodman ps\n\n# Show all containers (including stopped)\npodman ps -a\n</code></pre>"},{"location":"containers/podman/#managing-containers","title":"Managing Containers","text":"<pre><code># Stop a container\npodman stop container-name\n\n# Start a stopped container\npodman start container-name\n\n# Remove a container\npodman rm container-name\n\n# Execute command in running container\npodman exec -it container-name bash\n</code></pre>"},{"location":"containers/podman/#managing-images","title":"Managing Images","text":"<pre><code># List images\npodman images\n\n# Remove an image\npodman rmi image-name\n\n# Clean up unused images\npodman image prune\n</code></pre>"},{"location":"containers/podman/#mounting-volumes","title":"Mounting Volumes","text":"<p>To access your data and NAS directories in containers:</p> <pre><code># Mount your NAS home\npodman run -it \\\n  -v /nas/homes/your-username:/nas:Z \\\n  ubuntu:latest bash\n\n# Mount specific data directory\npodman run -it \\\n  -v /data/ERA5:/data/ERA5:Z \\\n  -v /nas/homes/your-username:/workspace:Z \\\n  ubuntu:latest bash\n</code></pre> <p>Note</p> <p>The <code>:Z</code> flag is important for SELinux contexts. Include it when mounting volumes.</p>"},{"location":"containers/podman/#using-sudo-inside-containers","title":"Using Sudo Inside Containers","text":"<p>Inside your container, you have full sudo access:</p> <pre><code># Enter container\npodman run -it ubuntu:latest bash\n\n# Inside container - install packages\nsudo apt update\nsudo apt install python3 python3-pip vim\npip3 install numpy pandas\n</code></pre>"},{"location":"containers/podman/#running-long-jobs","title":"Running Long Jobs","text":"<p>For jobs that take hours or days, use detached mode:</p> <pre><code># Start container in background\npodman run -d \\\n  --name data-processing \\\n  -v /data:/data:Z \\\n  -v /nas/homes/your-username:/workspace:Z \\\n  harbor.example.com/base/python:latest \\\n  python /workspace/process_data.py\n\n# Check logs\npodman logs data-processing\n\n# Follow logs in real-time\npodman logs -f data-processing\n\n# Check if still running\npodman ps\n\n# Stop if needed\npodman stop data-processing\n</code></pre>"},{"location":"containers/podman/#practical-example-data-processing","title":"Practical Example: Data Processing","text":"<p>[Content to be added: Complete example of a data processing workflow]</p> <pre><code># Pull our Python data science image\npodman pull harbor.example.com/base/python-datascience:latest\n\n# Run processing script\npodman run -it --rm \\\n  -v /data/ERA5:/input:Z \\\n  -v /nas/homes/your-username/results:/output:Z \\\n  harbor.example.com/base/python-datascience:latest \\\n  python /output/process_era5.py\n</code></pre>"},{"location":"containers/podman/#saving-your-work","title":"Saving Your Work","text":""},{"location":"containers/podman/#option-1-commit-changes","title":"Option 1: Commit Changes","text":"<p>If you've modified a container and want to save it:</p> <pre><code># Make changes in a container\npodman run -it --name my-work ubuntu:latest bash\n# (install things, make changes)\nexit\n\n# Commit to new image\npodman commit my-work my-custom-image:latest\n\n# Push to Harbor\npodman tag my-custom-image:latest harbor.example.com/your-project/my-custom-image:latest\npodman push harbor.example.com/your-project/my-custom-image:latest\n</code></pre>"},{"location":"containers/podman/#option-2-use-dockerfiles-recommended","title":"Option 2: Use Dockerfiles (Recommended)","text":"<p>See Building Your Containers for a better approach using Dockerfiles.</p>"},{"location":"containers/podman/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"containers/podman/#1-use-screen-or-tmux","title":"1. Use Screen or Tmux","text":"<p>For long-running jobs, use screen or tmux so your session persists:</p> <pre><code># Start a screen session\nscreen -S mywork\n\n# Run your container\npodman run ...\n\n# Detach with Ctrl+A then D\n\n# Reattach later\nscreen -r mywork\n</code></pre>"},{"location":"containers/podman/#2-check-resource-usage","title":"2. Check Resource Usage","text":"<p>[Content to be added: Monitoring CPU/memory usage]</p>"},{"location":"containers/podman/#3-clean-up-regularly","title":"3. Clean Up Regularly","text":"<p>[Content to be added: Removing old containers and images]</p>"},{"location":"containers/podman/#troubleshooting","title":"Troubleshooting","text":""},{"location":"containers/podman/#permission-denied","title":"Permission Denied","text":"<p>[Content to be added: Common permission issues]</p>"},{"location":"containers/podman/#out-of-space","title":"Out of Space","text":"<p>[Content to be added: Check quota, clean up]</p>"},{"location":"containers/podman/#container-wont-start","title":"Container Won't Start","text":"<p>[Content to be added: Common issues]</p> <p>Next Step: Learn about our Harbor Registry</p>"},{"location":"getting-started/account-setup/","title":"Getting Your Account","text":""},{"location":"getting-started/account-setup/#account-creation-process","title":"Account Creation Process","text":"<p>[Content to be added: Step-by-step process for new users to get an account]</p>"},{"location":"getting-started/account-setup/#prerequisites","title":"Prerequisites","text":"<p>[Content to be added: What information/approvals needed]</p>"},{"location":"getting-started/account-setup/#request-process","title":"Request Process","text":"<p>[Content to be added: Who to contact, what information to provide]</p>"},{"location":"getting-started/account-setup/#understanding-your-account","title":"Understanding Your Account","text":""},{"location":"getting-started/account-setup/#username-and-password","title":"Username and Password","text":"<p>[Content to be added: Username format, initial password, how to change]</p>"},{"location":"getting-started/account-setup/#your-two-home-directories","title":"Your Two Home Directories","text":"<p>Every user in the lab has two home directories:</p>"},{"location":"getting-started/account-setup/#1-local-home","title":"1. Local Home","text":"<ul> <li>Location: On each computing server (<code>/home/your-username</code>)</li> <li>Characteristics: Fast local storage</li> <li>Best for: Temporary files, active work, cache</li> <li>Note: Not shared between servers</li> </ul>"},{"location":"getting-started/account-setup/#2-nas-home","title":"2. NAS Home","text":"<ul> <li>Location: On the NAS (<code>/nas/homes/your-username</code>)</li> <li>Characteristics: Network storage, shared across all servers</li> <li>Best for: Important files, long-term storage, shared data</li> <li>Note: Accessible from all servers</li> </ul> <p>Warning</p> <p>Important files should be stored in your NAS home to ensure they're backed up and accessible from all servers.</p>"},{"location":"getting-started/account-setup/#web-portal-access","title":"Web Portal Access","text":"<p>[Content to be added: How to access the web portal]</p>"},{"location":"getting-started/account-setup/#enabling-nas-access","title":"Enabling NAS Access","text":"<p>[Content to be added: Steps to enable NAS home directory access via web portal]</p>"},{"location":"getting-started/account-setup/#ldap-account-manager","title":"LDAP Account Manager","text":"<p>The LDAP Account Manager is a web interface where you can:</p> <ul> <li>Change your password</li> <li>Upload SSH public keys</li> <li>View account information</li> <li>[Content to be added: Other capabilities]</li> </ul> <p>URL: [To be added]</p>"},{"location":"getting-started/account-setup/#initial-setup-checklist","title":"Initial Setup Checklist","text":"<ul> <li>[ ] Receive account credentials</li> <li>[ ] Log in to web portal</li> <li>[ ] Enable NAS access</li> <li>[ ] Change initial password</li> <li>[ ] Generate SSH keys (see SSH Setup)</li> <li>[ ] Upload SSH public key to LDAP Account Manager</li> </ul> <p>Next Step: Set up SSH &amp; Remote Access</p>"},{"location":"getting-started/hardware-overview/","title":"Hardware &amp; Resources Overview","text":""},{"location":"getting-started/hardware-overview/#infrastructure-diagram","title":"Infrastructure Diagram","text":"<p>[Content to be added: Consider adding a network/infrastructure diagram here]</p>"},{"location":"getting-started/hardware-overview/#core-server","title":"Core Server","text":"<p>Role: Central services and authentication</p> <p>The Core server is the backbone of our infrastructure. It runs:</p> <ul> <li>LDAP: User authentication system</li> <li>Harbor Registry: Private container registry</li> <li>EMQX: MQTT broker for sensor data</li> <li>LDAP Account Manager: Web-based user management</li> <li>InfluxDB: Time-series database for sensor data</li> <li>Traefik: Reverse proxy for web services</li> </ul> <p>Note</p> <p>Regular users don't directly interact with the Core server. It runs behind the scenes to provide services.</p>"},{"location":"getting-started/hardware-overview/#storage-systems","title":"Storage Systems","text":""},{"location":"getting-started/hardware-overview/#current-nas-80tb","title":"Current NAS (80TB)","text":"<p>Hostname: [To be added]</p> <p>Two main directories:</p> <ul> <li><code>/data</code>: Shared datasets (ERA5, IMERG, radar, satellite, gauge data)</li> <li><code>/homes</code>: User home directories (NAS home)</li> </ul>"},{"location":"getting-started/hardware-overview/#future-data-nas-18-bay","title":"Future Data NAS (18-bay)","text":"<p>[Content to be added: Plans for dedicated data NAS]</p>"},{"location":"getting-started/hardware-overview/#computing-servers","title":"Computing Servers","text":""},{"location":"getting-started/hardware-overview/#gpu-servers-simple-tasks","title":"GPU Servers - Simple Tasks","text":""},{"location":"getting-started/hardware-overview/#server-1-i7-rtx-3080-ti","title":"Server 1: i7 + RTX 3080 Ti","text":"<ul> <li>Hostname: [To be added]</li> <li>Purpose: Initial verification, basic experiments</li> <li>GPU: NVIDIA RTX 3080 Ti</li> <li>Special Notes: Users have sudo access (via dedicated sudo account)</li> </ul>"},{"location":"getting-started/hardware-overview/#server-2-i9-rtx-4090","title":"Server 2: i9 + RTX 4090","text":"<ul> <li>Hostname: [To be added]</li> <li>Purpose: Heavier experiments, deep learning</li> <li>GPU: NVIDIA RTX 4090</li> <li>Special Notes: Users have sudo access (via dedicated sudo account)</li> </ul>"},{"location":"getting-started/hardware-overview/#server-3-amd-5950-rtx-3090","title":"Server 3: AMD 5950 + RTX 3090","text":"<ul> <li>Hostname: [To be added]</li> <li>Purpose: General computation and experiments</li> <li>GPU: NVIDIA RTX 3090</li> <li>Special Notes: Users have sudo access (via dedicated sudo account)</li> </ul>"},{"location":"getting-started/hardware-overview/#cpu-server-data-processing","title":"CPU Server - Data Processing","text":""},{"location":"getting-started/hardware-overview/#threadripper-7965","title":"Threadripper 7965","text":"<ul> <li>Hostname: [To be added]</li> <li>Purpose: CPU-intensive data processing</li> <li>CPU: AMD Threadripper 7965 (24 cores)</li> <li>Special Notes:<ul> <li>No sudo access for regular users</li> <li>Use rootless Podman for containerized workflows</li> <li>Sudo available inside your own containers</li> </ul> </li> </ul>"},{"location":"getting-started/hardware-overview/#understanding-the-two-home-system","title":"Understanding the Two-Home System","text":"<p>Each user has two home directories:</p> <ol> <li>Local Home: On each computing server (faster, but not shared)</li> <li>NAS Home: On the NAS (shared across all servers, mounted via NFS)</li> </ol> <p>[Content to be added: More details about when to use each]</p>"},{"location":"getting-started/hardware-overview/#when-to-use-which-server","title":"When to Use Which Server?","text":"Task Recommended Server Quick data exploration Any GPU server Initial model training GPU servers (i7, i9, or 5950) Heavy deep learning GPU servers with 4090 or 3090 Large-scale data processing Threadripper Production runs Taiwan HPC <p>Next Step: Learn how to Get Your Account</p>"},{"location":"getting-started/welcome/","title":"Welcome &amp; Introduction","text":""},{"location":"getting-started/welcome/#about-this-documentation","title":"About This Documentation","text":"<p>This documentation is designed to help students and researchers in our Hydrometerology Lab effectively use our computing infrastructure. Whether you're an undergraduate student running your first analysis or a graduate student preparing for large-scale simulations, this guide will help you get started.</p>"},{"location":"getting-started/welcome/#lab-computing-infrastructure-overview","title":"Lab Computing Infrastructure Overview","text":"<p>Our lab has built a comprehensive computing infrastructure that includes:</p> <ul> <li>Authentication System: Centralized user management via LDAP</li> <li>Computing Servers: Multiple servers with GPU and CPU resources</li> <li>Storage: Large-scale NAS storage for datasets and user files</li> <li>Container Registry: Private Harbor registry for reproducible research</li> <li>HPC Access: Gateway to Taiwan's national HPC resources</li> </ul>"},{"location":"getting-started/welcome/#who-should-use-this-documentation","title":"Who Should Use This Documentation?","text":""},{"location":"getting-started/welcome/#new-students","title":"New Students","text":"<p>If you're new to the lab and need to learn the basics, follow the documentation in order starting from \"Getting Started\".</p>"},{"location":"getting-started/welcome/#experienced-users","title":"Experienced Users","text":"<p>If you already know Linux and SSH, you can jump directly to specific sections like Harbor Registry or Using SLURM.</p>"},{"location":"getting-started/welcome/#system-maintainers","title":"System Maintainers","text":"<p>Infrastructure and administration documentation is available in the Maintainer Documentation section.</p>"},{"location":"getting-started/welcome/#getting-help","title":"Getting Help","text":"<p>If you need assistance:</p> <ul> <li>Technical Issues: Contact the lab system administrator</li> <li>Account Problems: Use the LDAP Account Manager web portal</li> <li>Research Questions: Consult with your advisor or senior lab members</li> </ul>"},{"location":"getting-started/welcome/#prerequisites","title":"Prerequisites","text":"<p>To use our computing resources, you should:</p> <ul> <li>Have basic computer skills</li> <li>Be familiar with VSCode (or willing to learn)</li> <li>Have patience - learning Linux takes time, but it's worth it!</li> </ul> <p>Next Step: Learn about Why Linux?</p>"},{"location":"getting-started/why-linux/","title":"Why Linux?","text":""},{"location":"getting-started/why-linux/#introduction","title":"Introduction","text":"<p>All of our lab's computing servers run Linux. If you've only used Windows or macOS before, you might wonder why we use Linux for scientific computing. This page explains the reasons and what to expect.</p>"},{"location":"getting-started/why-linux/#why-scientists-use-linux","title":"Why Scientists Use Linux","text":""},{"location":"getting-started/why-linux/#1-performance-and-efficiency","title":"1. Performance and Efficiency","text":"<p>[Content to be added: Explain how Linux is lightweight and efficient for computational tasks]</p>"},{"location":"getting-started/why-linux/#2-remote-access","title":"2. Remote Access","text":"<p>[Content to be added: Explain SSH and remote computing]</p>"},{"location":"getting-started/why-linux/#3-package-management","title":"3. Package Management","text":"<p>[Content to be added: Explain how easy it is to install scientific software]</p>"},{"location":"getting-started/why-linux/#4-reproducibility","title":"4. Reproducibility","text":"<p>[Content to be added: Explain scripting and automation]</p>"},{"location":"getting-started/why-linux/#5-hpc-standard","title":"5. HPC Standard","text":"<p>[Content to be added: Explain that all HPC systems run Linux]</p>"},{"location":"getting-started/why-linux/#what-to-expect-as-a-new-user","title":"What to Expect as a New User","text":""},{"location":"getting-started/why-linux/#youll-use-the-command-line","title":"You'll Use the Command Line","text":"<p>[Content to be added: Brief introduction to terminal/command line]</p>"},{"location":"getting-started/why-linux/#its-different-but-learnable","title":"It's Different, But Learnable","text":"<p>[Content to be added: Encouragement and learning curve discussion]</p>"},{"location":"getting-started/why-linux/#you-dont-need-to-be-an-expert","title":"You Don't Need to Be an Expert","text":"<p>[Content to be added: Reassurance that they'll learn what they need]</p>"},{"location":"getting-started/why-linux/#linux-distributions","title":"Linux Distributions","text":"<p>[Content to be added: Brief mention of Ubuntu/Debian which most of your servers likely use]</p> <p>Next Step: Learn about our Hardware &amp; Resources</p>"},{"location":"hpc/modules/","title":"Environment Modules","text":""},{"location":"hpc/modules/#what-are-environment-modules","title":"What are Environment Modules?","text":"<p>HPC systems use environment modules to manage different software versions. Instead of installing software yourself, you load pre-installed modules.</p>"},{"location":"hpc/modules/#basic-commands","title":"Basic Commands","text":""},{"location":"hpc/modules/#module-avail-see-available-modules","title":"<code>module avail</code> - See Available Modules","text":"<pre><code>module avail\n</code></pre> <p>Lists all available modules.</p> <pre><code>module avail python\n</code></pre> <p>Lists modules matching \"python\".</p>"},{"location":"hpc/modules/#module-load-load-a-module","title":"<code>module load</code> - Load a Module","text":"<pre><code>module load python/3.10\nmodule load cuda/11.8\nmodule load singularity\n</code></pre>"},{"location":"hpc/modules/#module-list-show-loaded-modules","title":"<code>module list</code> - Show Loaded Modules","text":"<pre><code>module list\n</code></pre>"},{"location":"hpc/modules/#module-unload-unload-a-module","title":"<code>module unload</code> - Unload a Module","text":"<pre><code>module unload python/3.10\n</code></pre>"},{"location":"hpc/modules/#module-purge-unload-all","title":"<code>module purge</code> - Unload All","text":"<pre><code>module purge\n</code></pre> <p>Unloads all modules (useful for clean start).</p>"},{"location":"hpc/modules/#common-modules","title":"Common Modules","text":"<p>[Content to be added: Specific to Taiwan HPC]</p>"},{"location":"hpc/modules/#python","title":"Python","text":"<pre><code>module load python/3.10\n</code></pre>"},{"location":"hpc/modules/#cuda","title":"CUDA","text":"<pre><code>module load cuda/11.8\n</code></pre>"},{"location":"hpc/modules/#singularityapptainer","title":"Singularity/Apptainer","text":"<pre><code>module load singularity\n</code></pre>"},{"location":"hpc/modules/#using-modules-in-job-scripts","title":"Using Modules in Job Scripts","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=my_job\n#SBATCH --time=01:00:00\n\n# Load required modules\nmodule purge\nmodule load python/3.10\nmodule load cuda/11.8\nmodule load singularity\n\n# Run your job\nsingularity exec --nv my_image.sif python script.py\n</code></pre>"},{"location":"hpc/modules/#module-vs-containers","title":"Module vs Containers","text":""},{"location":"hpc/modules/#when-to-use-modules","title":"When to Use Modules","text":"<ul> <li>Quick tasks using standard software</li> <li>Software already optimized for the HPC</li> <li>Simple preprocessing</li> </ul>"},{"location":"hpc/modules/#when-to-use-containers","title":"When to Use Containers","text":"<ul> <li>Complex dependency chains</li> <li>Reproducible research</li> <li>Software not available as module</li> <li>Same environment as your lab work</li> </ul>"},{"location":"hpc/modules/#combining-both","title":"Combining Both","text":"<p>You can use both! Load the singularity module, then run your container:</p> <pre><code>module load singularity\nsingularity exec my_container.sif python script.py\n</code></pre>"},{"location":"hpc/modules/#creating-module-loading-scripts","title":"Creating Module Loading Scripts","text":"<p>For convenience, create a script:</p> <pre><code># save as setup.sh\nmodule purge\nmodule load python/3.10\nmodule load cuda/11.8\nmodule load singularity\n\n# Use it in your jobs\nsource setup.sh\n</code></pre>"},{"location":"hpc/modules/#checking-module-details","title":"Checking Module Details","text":"<pre><code># Show what a module does\nmodule show python/3.10\n</code></pre> <p>Next: Explore Maintainer Documentation (for system administrators)</p>"},{"location":"hpc/preparing/","title":"Preparing for Taiwan HPC","text":""},{"location":"hpc/preparing/#introduction","title":"Introduction","text":"<p>Taiwan's national HPC systems provide massive computational resources for research. This guide helps you transition from lab servers to HPC.</p>"},{"location":"hpc/preparing/#why-use-hpc","title":"Why Use HPC?","text":"<p>[Content to be added: When lab resources aren't enough]</p> <ul> <li>Very long-running jobs (days to weeks)</li> <li>Need for many GPUs simultaneously</li> <li>Large-scale parallel computing</li> <li>Production research runs</li> </ul>"},{"location":"hpc/preparing/#how-containers-help","title":"How Containers Help","text":"<p>If you've been using containers on Threadripper, transitioning to HPC is much easier:</p> <ol> <li>Same Environment: Your container runs the same way on HPC</li> <li>Tested Workflow: You've already debugged on lab servers</li> <li>Portable: No need to reinstall everything on HPC</li> </ol>"},{"location":"hpc/preparing/#container-formats-on-hpc","title":"Container Formats on HPC","text":"<p>Most HPC systems use Singularity (now called Apptainer) instead of Docker/Podman:</p> <ul> <li>Designed for HPC environments</li> <li>No root required</li> <li>Compatible with Docker images</li> </ul>"},{"location":"hpc/preparing/#converting-your-images","title":"Converting Your Images","text":"<p>[Content to be added: How to convert Podman/Docker images to Singularity]</p> <pre><code># On HPC, pull from Docker Hub or Harbor\nsingularity pull docker://harbor.example.com/your-project/my-image:latest\n\n# This creates a .sif file you can use\n</code></pre>"},{"location":"hpc/preparing/#accessing-taiwan-hpc","title":"Accessing Taiwan HPC","text":"<p>[Content to be added: How to get an account]</p>"},{"location":"hpc/preparing/#account-setup","title":"Account Setup","text":"<p>[Content to be added: Application process]</p>"},{"location":"hpc/preparing/#connecting","title":"Connecting","text":"<p>[Content to be added: SSH to HPC, VPN requirements if any]</p>"},{"location":"hpc/preparing/#transferring-data","title":"Transferring Data","text":"<p>[Content to be added: Moving data between lab and HPC]</p>"},{"location":"hpc/preparing/#using-our-nas","title":"Using Our NAS","text":"<p>[Content to be added: If there's any shared storage or transfer node]</p>"},{"location":"hpc/preparing/#best-practices","title":"Best Practices","text":"<p>[Content to be added: Don't transfer raw datasets if HPC already has them]</p> <p>Next Step: Learn about Using SLURM</p>"},{"location":"hpc/slurm/","title":"Using SLURM","text":""},{"location":"hpc/slurm/#what-is-slurm","title":"What is SLURM?","text":"<p>SLURM (Simple Linux Utility for Resource Management) is the job scheduler used on most HPC systems, including Taiwan's national systems.</p> <p>Unlike lab servers where you SSH in and run commands directly, on HPC you submit jobs to a queue and SLURM schedules when they run.</p>"},{"location":"hpc/slurm/#basic-concepts","title":"Basic Concepts","text":""},{"location":"hpc/slurm/#partitionqueue","title":"Partition/Queue","text":"<p>[Content to be added: Different types of nodes (GPU, CPU, memory, etc.)]</p>"},{"location":"hpc/slurm/#job","title":"Job","text":"<p>[Content to be added: A script that SLURM runs for you]</p>"},{"location":"hpc/slurm/#node","title":"Node","text":"<p>[Content to be added: Individual server in the HPC cluster]</p>"},{"location":"hpc/slurm/#key-commands","title":"Key Commands","text":""},{"location":"hpc/slurm/#sinfo-cluster-information","title":"<code>sinfo</code> - Cluster Information","text":"<pre><code>sinfo\n</code></pre> <p>Shows available partitions and node status.</p>"},{"location":"hpc/slurm/#squeue-queue-status","title":"<code>squeue</code> - Queue Status","text":"<pre><code># See all jobs in queue\nsqueue\n\n# See only your jobs\nsqueue -u your-username\n</code></pre>"},{"location":"hpc/slurm/#sbatch-submit-a-job","title":"<code>sbatch</code> - Submit a Job","text":"<pre><code>sbatch job_script.sh\n</code></pre> <p>Submits a job script to the queue.</p>"},{"location":"hpc/slurm/#scancel-cancel-a-job","title":"<code>scancel</code> - Cancel a Job","text":"<pre><code>scancel job-id\n</code></pre>"},{"location":"hpc/slurm/#sacct-job-accounting","title":"<code>sacct</code> - Job Accounting","text":"<pre><code>sacct\n</code></pre> <p>Shows information about completed jobs.</p>"},{"location":"hpc/slurm/#job-scripts","title":"Job Scripts","text":"<p>A SLURM job script is a bash script with special directives:</p>"},{"location":"hpc/slurm/#basic-example","title":"Basic Example","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=my_job\n#SBATCH --output=output_%j.txt\n#SBATCH --error=error_%j.txt\n#SBATCH --time=02:00:00\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=16G\n\n# Load modules or activate environment\nmodule load singularity\n\n# Run your containerized application\nsingularity exec --nv my_image.sif python my_script.py\n</code></pre>"},{"location":"hpc/slurm/#common-sbatch-options","title":"Common SBATCH Options","text":"Option Description Example <code>--job-name</code> Name for your job <code>--job-name=data_proc</code> <code>--output</code> Output file <code>--output=out_%j.txt</code> <code>--error</code> Error file <code>--error=err_%j.txt</code> <code>--time</code> Max runtime <code>--time=24:00:00</code> <code>--partition</code> Queue to use <code>--partition=gpu</code> <code>--gres</code> Generic resources (GPUs) <code>--gres=gpu:2</code> <code>--cpus-per-task</code> CPUs per task <code>--cpus-per-task=8</code> <code>--mem</code> Memory <code>--mem=32G</code> <code>--nodes</code> Number of nodes <code>--nodes=2</code> <p>[Content to be added: More options specific to Taiwan HPC]</p>"},{"location":"hpc/slurm/#using-containers-in-slurm","title":"Using Containers in SLURM","text":""},{"location":"hpc/slurm/#with-singularity","title":"With Singularity","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=container_job\n#SBATCH --output=output_%j.txt\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n\n# Use --nv flag for GPU access\nsingularity exec --nv \\\n  --bind /scratch:/scratch \\\n  my_image.sif \\\n  python /workspace/train_model.py\n</code></pre>"},{"location":"hpc/slurm/#monitoring-jobs","title":"Monitoring Jobs","text":""},{"location":"hpc/slurm/#check-status","title":"Check Status","text":"<pre><code>squeue -u your-username\n</code></pre>"},{"location":"hpc/slurm/#view-output","title":"View Output","text":"<pre><code># While running (if output file exists)\ntail -f output_12345.txt\n\n# After completion\ncat output_12345.txt\n</code></pre>"},{"location":"hpc/slurm/#job-efficiency","title":"Job Efficiency","text":"<p>[Content to be added: Checking if you requested appropriate resources]</p>"},{"location":"hpc/slurm/#best-practices","title":"Best Practices","text":""},{"location":"hpc/slurm/#1-test-first","title":"1. Test First","text":"<p>[Content to be added: Test on lab servers before HPC]</p>"},{"location":"hpc/slurm/#2-request-appropriate-resources","title":"2. Request Appropriate Resources","text":"<p>[Content to be added: Don't over-request, blocks others]</p>"},{"location":"hpc/slurm/#3-use-array-jobs","title":"3. Use Array Jobs","text":"<p>[Content to be added: For many similar jobs]</p> <pre><code>#SBATCH --array=1-10\n</code></pre>"},{"location":"hpc/slurm/#4-save-results-regularly","title":"4. Save Results Regularly","text":"<p>[Content to be added: Checkpoint your work]</p>"},{"location":"hpc/slurm/#example-workflows","title":"Example Workflows","text":"<p>[Content to be added: Complete examples for common tasks]</p> <p>Next Step: Learn about Environment Modules</p>"},{"location":"maintainer/core-server/","title":"Core Server Architecture","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers. Regular users do not need this information.</p>"},{"location":"maintainer/core-server/#overview","title":"Overview","text":"<p>The Core server is the central infrastructure component that provides authentication, container registry, and sensor data services.</p> <p>Specifications: - CPU: Intel i9 - Role: Infrastructure services - OS: [To be added]</p>"},{"location":"maintainer/core-server/#services-architecture","title":"Services Architecture","text":""},{"location":"maintainer/core-server/#service-stack","title":"Service Stack","text":"<p>All services run in Docker containers, orchestrated via Docker Compose, with Traefik as the reverse proxy.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Traefik (Reverse Proxy)     \u2502\n\u2502         Port 80/443                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                       \u2502\n       \u25bc                       \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Harbor  \u2502           \u2502   LAM    \u2502\n  \u2502 (8080)  \u2502           \u2502  (8081)  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                       \u2502\n       \u25bc                       \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  EMQX   \u2502           \u2502 InfluxDB \u2502\n  \u2502 (1883)  \u2502           \u2502  (8086)  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"maintainer/core-server/#ldap-server","title":"LDAP Server","text":"<p>Status: Runs natively (not containerized)</p> <p>[Content to be added]</p> <ul> <li>Installation method</li> <li>Configuration files</li> <li>Schema customizations</li> <li>Backup procedures</li> </ul>"},{"location":"maintainer/core-server/#harbor-registry","title":"Harbor Registry","text":"<p>Container: [To be added] Port: 8080 (internal), proxied via Traefik</p> <p>[Content to be added]</p> <ul> <li>Docker Compose configuration</li> <li>Volume mounts</li> <li>Database backend</li> <li>TLS configuration</li> <li>Backup and restore procedures</li> <li>Adding new projects</li> <li>User management</li> </ul>"},{"location":"maintainer/core-server/#emqx-mqtt-broker","title":"EMQX (MQTT Broker)","text":"<p>Container: [To be added] Port: 1883 (MQTT), 18083 (Dashboard)</p> <p>[Content to be added]</p> <ul> <li>Purpose: Sensor data ingestion</li> <li>Configuration</li> <li>ACL rules</li> <li>Integration with InfluxDB</li> <li>Monitoring</li> </ul>"},{"location":"maintainer/core-server/#ldap-account-manager-lam","title":"LDAP Account Manager (LAM)","text":"<p>Container: [To be added] Port: 8081 (internal), proxied via Traefik</p> <p>[Content to be added]</p> <ul> <li>Configuration</li> <li>LDAP connection settings</li> <li>User self-service features</li> <li>SSH key management</li> </ul>"},{"location":"maintainer/core-server/#sensor-data-acquisition-system","title":"Sensor Data Acquisition System","text":"<p>Container: [To be added]</p> <p>[Content to be added]</p> <ul> <li>Architecture</li> <li>Data flow</li> <li>Integration with EMQX</li> <li>Data processing pipeline</li> </ul>"},{"location":"maintainer/core-server/#influxdb","title":"InfluxDB","text":"<p>Container: [To be added] Port: 8086</p> <p>[Content to be added]</p> <ul> <li>Purpose: Time-series storage for sensor data</li> <li>Configuration</li> <li>Retention policies</li> <li>Backup procedures</li> <li>Querying and visualization</li> </ul>"},{"location":"maintainer/core-server/#traefik","title":"Traefik","text":"<p>Container: [To be added] Port: 80, 443</p> <p>[Content to be added]</p> <ul> <li>Configuration files</li> <li>Dynamic configuration</li> <li>TLS/SSL certificates (Let's Encrypt?)</li> <li>Routing rules</li> <li>Adding new services</li> </ul>"},{"location":"maintainer/core-server/#network-architecture","title":"Network Architecture","text":"<p>[Content to be added]</p> <ul> <li>Network topology</li> <li>Firewall rules</li> <li>Port forwarding</li> <li>DNS configuration</li> </ul>"},{"location":"maintainer/core-server/#file-system-structure","title":"File System Structure","text":"<pre><code>/opt/services/\n\u251c\u2500\u2500 harbor/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 data/\n\u251c\u2500\u2500 emqx/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 data/\n\u251c\u2500\u2500 influxdb/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 data/\n\u251c\u2500\u2500 lam/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 config/\n\u2514\u2500\u2500 traefik/\n    \u251c\u2500\u2500 docker-compose.yml\n    \u251c\u2500\u2500 traefik.yml\n    \u2514\u2500\u2500 dynamic/\n</code></pre> <p>[Content to be added: Actual structure]</p>"},{"location":"maintainer/core-server/#docker-compose-files","title":"Docker Compose Files","text":""},{"location":"maintainer/core-server/#example-harbor","title":"Example: Harbor","text":"<p>[Content to be added: Actual docker-compose.yml]</p>"},{"location":"maintainer/core-server/#example-emqx","title":"Example: EMQX","text":"<p>[Content to be added: Actual docker-compose.yml]</p>"},{"location":"maintainer/core-server/#backup-procedures","title":"Backup Procedures","text":"<p>[Content to be added]</p> <ul> <li>What needs to be backed up</li> <li>Backup schedule</li> <li>Backup locations</li> <li>Restore procedures</li> </ul>"},{"location":"maintainer/core-server/#monitoring","title":"Monitoring","text":"<p>[Content to be added]</p> <ul> <li>Service health checks</li> <li>Logging</li> <li>Alerting</li> </ul>"},{"location":"maintainer/core-server/#troubleshooting","title":"Troubleshooting","text":"<p>[Content to be added]</p> <ul> <li>Common issues</li> <li>Log locations</li> <li>Service restart procedures</li> <li>Network connectivity issues</li> </ul>"},{"location":"maintainer/core-server/#adding-new-services","title":"Adding New Services","text":"<p>[Content to be added]</p> <ul> <li>Steps to add a new containerized service</li> <li>Traefik integration</li> <li>LDAP authentication integration</li> </ul> <p>Next: Server Administration</p>"},{"location":"maintainer/dockerfiles/","title":"Service Dockerfiles &amp; Design","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers.</p>"},{"location":"maintainer/dockerfiles/#philosophy","title":"Philosophy","text":"<p>Our service architecture follows these principles:</p> <ol> <li>Containerization: All services (except LDAP) run in containers</li> <li>Reproducibility: Services can be rebuilt and redeployed from configuration</li> <li>Traefik Integration: All web services are proxied through Traefik</li> <li>Data Persistence: Data is stored in volumes, not containers</li> <li>Simplicity: Keep configurations straightforward and well-documented</li> </ol>"},{"location":"maintainer/dockerfiles/#repository-structure","title":"Repository Structure","text":"<p>[Content to be added: Where service configurations are stored]</p> <pre><code>/opt/services/\n\u251c\u2500\u2500 docker-compose.yml         # Main compose file?\n\u251c\u2500\u2500 harbor/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 config/\n\u251c\u2500\u2500 emqx/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 config/\n\u251c\u2500\u2500 influxdb/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u2514\u2500\u2500 config/\n\u2514\u2500\u2500 traefik/\n    \u251c\u2500\u2500 docker-compose.yml\n    \u251c\u2500\u2500 traefik.yml\n    \u2514\u2500\u2500 dynamic/\n</code></pre>"},{"location":"maintainer/dockerfiles/#traefik-configuration","title":"Traefik Configuration","text":"<p>Traefik acts as the reverse proxy for all web services.</p>"},{"location":"maintainer/dockerfiles/#main-configuration","title":"Main Configuration","text":"<p>File: <code>traefik.yml</code></p> <p>[Content to be added: Actual configuration]</p> <pre><code>entryPoints:\n  web:\n    address: \":80\"\n  websecure:\n    address: \":443\"\n\nproviders:\n  docker:\n    exposedByDefault: false\n  file:\n    directory: /etc/traefik/dynamic\n\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      email: admin@example.com\n      storage: /letsencrypt/acme.json\n      httpChallenge:\n        entryPoint: web\n</code></pre>"},{"location":"maintainer/dockerfiles/#dynamic-configuration","title":"Dynamic Configuration","text":"<p>[Content to be added: How services register with Traefik]</p>"},{"location":"maintainer/dockerfiles/#harbor-configuration","title":"Harbor Configuration","text":""},{"location":"maintainer/dockerfiles/#docker-compose","title":"Docker Compose","text":"<p>[Content to be added: Actual docker-compose.yml]</p> <pre><code>version: '3'\nservices:\n  harbor:\n    image: goharbor/harbor:latest\n    container_name: harbor\n    volumes:\n      - harbor_data:/data\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.harbor.rule=Host(`harbor.example.com`)\"\n      - \"traefik.http.services.harbor.loadbalancer.server.port=8080\"\n    networks:\n      - traefik_network\n\nvolumes:\n  harbor_data:\n\nnetworks:\n  traefik_network:\n    external: true\n</code></pre>"},{"location":"maintainer/dockerfiles/#design-rationale","title":"Design Rationale","text":"<p>[Content to be added]</p> <ul> <li>Why these specific configurations</li> <li>Volume mount decisions</li> <li>Security considerations</li> </ul>"},{"location":"maintainer/dockerfiles/#emqx-configuration","title":"EMQX Configuration","text":""},{"location":"maintainer/dockerfiles/#docker-compose_1","title":"Docker Compose","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#design-rationale_1","title":"Design Rationale","text":"<p>[Content to be added]</p> <ul> <li>Why EMQX over other MQTT brokers</li> <li>Configuration choices</li> <li>Integration with InfluxDB</li> </ul>"},{"location":"maintainer/dockerfiles/#influxdb-configuration","title":"InfluxDB Configuration","text":""},{"location":"maintainer/dockerfiles/#docker-compose_2","title":"Docker Compose","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#design-rationale_2","title":"Design Rationale","text":"<p>[Content to be added]</p> <ul> <li>Retention policies</li> <li>Data organization</li> <li>Backup integration</li> </ul>"},{"location":"maintainer/dockerfiles/#ldap-account-manager","title":"LDAP Account Manager","text":""},{"location":"maintainer/dockerfiles/#docker-compose_3","title":"Docker Compose","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#design-rationale_3","title":"Design Rationale","text":"<p>[Content to be added]</p> <ul> <li>LDAP connection security</li> <li>User self-service features enabled</li> </ul>"},{"location":"maintainer/dockerfiles/#sensor-data-acquisition","title":"Sensor Data Acquisition","text":""},{"location":"maintainer/dockerfiles/#custom-service","title":"Custom Service","text":"<p>[Content to be added]</p> <ul> <li>Dockerfile for the service</li> <li>Python/Node.js code structure</li> <li>Why certain libraries were chosen</li> </ul>"},{"location":"maintainer/dockerfiles/#dockerfile","title":"Dockerfile","text":"<p>[Content to be added: Actual Dockerfile]</p> <pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY src/ ./src/\n\nCMD [\"python\", \"src/main.py\"]\n</code></pre>"},{"location":"maintainer/dockerfiles/#design-rationale_4","title":"Design Rationale","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#network-architecture","title":"Network Architecture","text":""},{"location":"maintainer/dockerfiles/#docker-networks","title":"Docker Networks","text":"<p>[Content to be added]</p> <pre><code>networks:\n  traefik_network:\n    name: traefik_network\n  backend:\n    name: backend\n    internal: true\n</code></pre>"},{"location":"maintainer/dockerfiles/#why-this-design","title":"Why This Design","text":"<p>[Content to be added]</p> <ul> <li>Separation of public and internal services</li> <li>Security boundaries</li> </ul>"},{"location":"maintainer/dockerfiles/#secrets-management","title":"Secrets Management","text":"<p>[Content to be added]</p> <ul> <li>How secrets are stored</li> <li>Environment variables</li> <li>Docker secrets</li> <li>Rotation procedures</li> </ul>"},{"location":"maintainer/dockerfiles/#backup-strategy","title":"Backup Strategy","text":"<p>[Content to be added]</p> <ul> <li>What gets backed up</li> <li>Backup automation</li> <li>Volume snapshots</li> <li>Configuration backups</li> </ul>"},{"location":"maintainer/dockerfiles/#deployment-procedures","title":"Deployment Procedures","text":""},{"location":"maintainer/dockerfiles/#initial-deployment","title":"Initial Deployment","text":"<p>[Content to be added]</p> <pre><code># Clone configurations\ngit clone ...\n\n# Set up environment\ncp .env.example .env\nvim .env\n\n# Start services\ndocker-compose up -d\n</code></pre>"},{"location":"maintainer/dockerfiles/#updating-services","title":"Updating Services","text":"<p>[Content to be added]</p> <ul> <li>Rolling updates</li> <li>Downtime considerations</li> <li>Rollback procedures</li> </ul>"},{"location":"maintainer/dockerfiles/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"maintainer/dockerfiles/#log-collection","title":"Log Collection","text":"<p>[Content to be added]</p> <ul> <li>Where logs are stored</li> <li>Log rotation</li> <li>Centralized logging (if implemented)</li> </ul>"},{"location":"maintainer/dockerfiles/#health-checks","title":"Health Checks","text":"<p>[Content to be added]</p> <ul> <li>Docker health checks</li> <li>External monitoring</li> </ul>"},{"location":"maintainer/dockerfiles/#troubleshooting","title":"Troubleshooting","text":""},{"location":"maintainer/dockerfiles/#common-issues","title":"Common Issues","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#service-wont-start","title":"Service Won't Start","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#network-connectivity","title":"Network Connectivity","text":"<p>[Content to be added]</p>"},{"location":"maintainer/dockerfiles/#volume-permission-issues","title":"Volume Permission Issues","text":"<p>[Content to be added]</p> <p>Next: Storage Infrastructure</p>"},{"location":"maintainer/roadmap/","title":"Future Roadmap &amp; Maintenance","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers.</p>"},{"location":"maintainer/roadmap/#planned-upgrades","title":"Planned Upgrades","text":""},{"location":"maintainer/roadmap/#new-data-nas-deployment","title":"New Data NAS Deployment","text":"<p>Status: Hardware acquired, not yet configured Timeline: [To be added]</p> <p>Goals: - Dedicate 18-bay NAS for research datasets - Keep 80TB NAS for user homes - Improve data organization - Increase total storage capacity</p> <p>Tasks: - [ ] RAID configuration - [ ] Network setup - [ ] Data migration planning - [ ] NFS export configuration - [ ] Update compute server mounts - [ ] Migrate data from old NAS - [ ] Update documentation</p>"},{"location":"maintainer/roadmap/#infrastructure-improvements","title":"Infrastructure Improvements","text":"<p>[Content to be added: Other planned improvements]</p> <p>Possible areas: - Monitoring and alerting system - Centralized logging - Automated backups - Configuration management (Ansible?) - Documentation updates</p>"},{"location":"maintainer/roadmap/#maintenance-calendar","title":"Maintenance Calendar","text":""},{"location":"maintainer/roadmap/#daily-tasks","title":"Daily Tasks","text":"<p>[Content to be added]</p> <ul> <li>Monitor service status</li> <li>Check backup logs</li> <li>Review disk space</li> </ul>"},{"location":"maintainer/roadmap/#weekly-tasks","title":"Weekly Tasks","text":"<p>[Content to be added]</p> <ul> <li>Review user disk usage</li> <li>Check for system updates</li> <li>Review sensor data continuity</li> </ul>"},{"location":"maintainer/roadmap/#monthly-tasks","title":"Monthly Tasks","text":"<p>[Content to be added]</p> <ul> <li>System updates</li> <li>Security patches</li> <li>Backup restore testing</li> <li>Documentation updates</li> </ul>"},{"location":"maintainer/roadmap/#quarterly-tasks","title":"Quarterly Tasks","text":"<p>[Content to be added]</p> <ul> <li>RAID scrubbing verification</li> <li>Disaster recovery drill</li> <li>Access review</li> <li>Hardware health check</li> </ul>"},{"location":"maintainer/roadmap/#annual-tasks","title":"Annual Tasks","text":"<p>[Content to be added]</p> <ul> <li>Hardware refresh planning</li> <li>Capacity planning review</li> <li>Security audit</li> <li>Documentation review</li> </ul>"},{"location":"maintainer/roadmap/#known-issues","title":"Known Issues","text":"<p>[Content to be added: Document any known issues or workarounds]</p>"},{"location":"maintainer/roadmap/#issue-1-description","title":"Issue 1: [Description]","text":"<p>[Content to be added]</p> <p>Impact: ... Workaround: ... Permanent Fix: ...</p>"},{"location":"maintainer/roadmap/#future-considerations","title":"Future Considerations","text":""},{"location":"maintainer/roadmap/#scaling-compute-resources","title":"Scaling Compute Resources","text":"<p>[Content to be added]</p> <ul> <li>When to add more servers</li> <li>Cloud burst capacity</li> <li>HPC resource management</li> </ul>"},{"location":"maintainer/roadmap/#storage-scaling","title":"Storage Scaling","text":"<p>[Content to be added]</p> <ul> <li>When to expand NAS</li> <li>Tiered storage strategies</li> <li>Cloud storage integration</li> </ul>"},{"location":"maintainer/roadmap/#security-enhancements","title":"Security Enhancements","text":"<p>[Content to be added]</p> <ul> <li>Multi-factor authentication</li> <li>Intrusion detection</li> <li>Network segmentation</li> </ul>"},{"location":"maintainer/roadmap/#user-experience","title":"User Experience","text":"<p>[Content to be added]</p> <ul> <li>Web-based interfaces</li> <li>Job submission portal</li> <li>Self-service tools</li> </ul>"},{"location":"maintainer/roadmap/#decommissioning","title":"Decommissioning","text":""},{"location":"maintainer/roadmap/#old-hardware","title":"Old Hardware","text":"<p>[Content to be added]</p> <ul> <li>Procedures for retiring old servers</li> <li>Data migration</li> <li>Disposal or repurposing</li> </ul>"},{"location":"maintainer/roadmap/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"maintainer/roadmap/#critical-service-failure","title":"Critical Service Failure","text":"<p>[Content to be added]</p>"},{"location":"maintainer/roadmap/#core-server-down","title":"Core Server Down","text":"<p>[Content to be added]</p> <ol> <li>Impact assessment</li> <li>Immediate actions</li> <li>Communication plan</li> <li>Recovery steps</li> </ol>"},{"location":"maintainer/roadmap/#nas-failure","title":"NAS Failure","text":"<p>[Content to be added]</p> <ol> <li>Impact assessment</li> <li>Immediate actions</li> <li>Restore from backup</li> <li>Temporary alternatives</li> </ol>"},{"location":"maintainer/roadmap/#network-outage","title":"Network Outage","text":"<p>[Content to be added]</p>"},{"location":"maintainer/roadmap/#contact-information","title":"Contact Information","text":"<p>[Content to be added]</p> <ul> <li>IT support contacts</li> <li>Vendor support contacts</li> <li>Emergency escalation</li> </ul>"},{"location":"maintainer/roadmap/#documentation-maintenance","title":"Documentation Maintenance","text":""},{"location":"maintainer/roadmap/#keeping-documentation-updated","title":"Keeping Documentation Updated","text":"<p>This documentation should be updated:</p> <ul> <li>When new hardware is added</li> <li>When services are modified</li> <li>When procedures change</li> <li>When issues are discovered and resolved</li> </ul>"},{"location":"maintainer/roadmap/#documentation-review","title":"Documentation Review","text":"<p>[Content to be added]</p> <ul> <li>Who is responsible for updates</li> <li>Review schedule</li> <li>Version control</li> </ul>"},{"location":"maintainer/roadmap/#knowledge-transfer","title":"Knowledge Transfer","text":""},{"location":"maintainer/roadmap/#onboarding-new-administrators","title":"Onboarding New Administrators","text":"<p>[Content to be added]</p> <ul> <li>Required reading</li> <li>Training procedures</li> <li>Shadow period</li> <li>Access provisioning</li> </ul>"},{"location":"maintainer/roadmap/#offboarding","title":"Offboarding","text":"<p>[Content to be added]</p> <ul> <li>Knowledge transfer</li> <li>Access revocation</li> <li>Documentation of decisions</li> </ul> <p>End of Maintainer Documentation</p> <p>Return to Home or see Reference Materials</p>"},{"location":"maintainer/sensors/","title":"Weather Sensor Systems","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers.</p>"},{"location":"maintainer/sensors/#overview","title":"Overview","text":"<p>The lab operates several weather sensors that collect real-time meteorological data. Data flows through MQTT (EMQX) and is stored in InfluxDB.</p>"},{"location":"maintainer/sensors/#sensor-inventory","title":"Sensor Inventory","text":"<p>[Content to be added: List of all sensors]</p>"},{"location":"maintainer/sensors/#sensor-1-type","title":"Sensor 1: [Type]","text":"<ul> <li>Location: [To be added]</li> <li>Model: [To be added]</li> <li>Measurements: Temperature, humidity, pressure, etc.</li> <li>Data Rate: [To be added]</li> <li>Status: Active/Inactive</li> </ul>"},{"location":"maintainer/sensors/#sensor-2-type","title":"Sensor 2: [Type]","text":"<p>[Content to be added]</p>"},{"location":"maintainer/sensors/#data-flow-architecture","title":"Data Flow Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      MQTT       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Sensors  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502  EMQX    \u2502\u2500\u2500\u2500\u2500&gt; \u2502  InfluxDB    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502 Subscribers  \u2502\n                           \u2502 (Processing) \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"maintainer/sensors/#emqx-configuration","title":"EMQX Configuration","text":""},{"location":"maintainer/sensors/#mqtt-topics","title":"MQTT Topics","text":"<p>[Content to be added: Topic structure]</p> <pre><code>lab/weather/sensor1/temperature\nlab/weather/sensor1/humidity\nlab/weather/sensor2/temperature\n...\n</code></pre>"},{"location":"maintainer/sensors/#acl-rules","title":"ACL Rules","text":"<p>[Content to be added: Who can publish/subscribe]</p>"},{"location":"maintainer/sensors/#authentication","title":"Authentication","text":"<p>[Content to be added: How sensors authenticate to MQTT]</p>"},{"location":"maintainer/sensors/#data-acquisition-system","title":"Data Acquisition System","text":""},{"location":"maintainer/sensors/#architecture","title":"Architecture","text":"<p>[Content to be added]</p> <ul> <li>How data is collected from sensors</li> <li>Data preprocessing</li> <li>Publishing to MQTT</li> </ul>"},{"location":"maintainer/sensors/#container-configuration","title":"Container Configuration","text":"<p>Location: [To be added]</p> <p>[Content to be added: Docker compose configuration]</p>"},{"location":"maintainer/sensors/#code-repository","title":"Code Repository","text":"<p>[Content to be added: Where the acquisition system code is stored]</p>"},{"location":"maintainer/sensors/#influxdb-storage","title":"InfluxDB Storage","text":""},{"location":"maintainer/sensors/#database-structure","title":"Database Structure","text":"<p>[Content to be added]</p> <ul> <li>Database name</li> <li>Measurement names</li> <li>Tags and fields</li> <li>Retention policies</li> </ul>"},{"location":"maintainer/sensors/#querying-data","title":"Querying Data","text":"<pre><code>-- Example queries\nSELECT * FROM \"weather_data\"\nWHERE time &gt; now() - 24h\n\nSELECT mean(\"temperature\")\nFROM \"sensor_readings\"\nWHERE time &gt; now() - 7d\nGROUP BY time(1h)\n</code></pre>"},{"location":"maintainer/sensors/#sensor-maintenance","title":"Sensor Maintenance","text":""},{"location":"maintainer/sensors/#physical-maintenance","title":"Physical Maintenance","text":"<p>[Content to be added]</p> <ul> <li>Cleaning schedule</li> <li>Calibration procedures</li> <li>Battery replacement (if applicable)</li> </ul>"},{"location":"maintainer/sensors/#software-maintenance","title":"Software Maintenance","text":"<p>[Content to be added]</p> <ul> <li>Firmware updates</li> <li>Configuration backups</li> <li>Testing procedures</li> </ul>"},{"location":"maintainer/sensors/#adding-a-new-sensor","title":"Adding a New Sensor","text":"<p>[Content to be added: Step-by-step procedure]</p> <ol> <li>Physical installation</li> <li>Network configuration</li> <li>MQTT topic assignment</li> <li>Update data acquisition system</li> <li>Configure InfluxDB measurements</li> <li>Testing and verification</li> </ol>"},{"location":"maintainer/sensors/#troubleshooting","title":"Troubleshooting","text":""},{"location":"maintainer/sensors/#sensor-not-reporting","title":"Sensor Not Reporting","text":"<p>[Content to be added]</p> <ul> <li>Check network connectivity</li> <li>Verify MQTT connection</li> <li>Check sensor logs</li> <li>Physical inspection</li> </ul>"},{"location":"maintainer/sensors/#data-gaps","title":"Data Gaps","text":"<p>[Content to be added]</p> <ul> <li>Identifying missing data</li> <li>Investigation procedures</li> <li>Backfilling if possible</li> </ul>"},{"location":"maintainer/sensors/#mqtt-issues","title":"MQTT Issues","text":"<p>[Content to be added]</p> <ul> <li>Connection problems</li> <li>Authentication failures</li> <li>Topic subscription issues</li> </ul>"},{"location":"maintainer/sensors/#data-access","title":"Data Access","text":""},{"location":"maintainer/sensors/#real-time-monitoring","title":"Real-Time Monitoring","text":"<p>[Content to be added: Dashboard or monitoring tools]</p>"},{"location":"maintainer/sensors/#historical-data","title":"Historical Data","text":"<p>[Content to be added: How to query historical data]</p>"},{"location":"maintainer/sensors/#data-export","title":"Data Export","text":"<p>[Content to be added: Procedures for exporting data]</p>"},{"location":"maintainer/sensors/#backup-and-recovery","title":"Backup and Recovery","text":"<p>[Content to be added]</p> <ul> <li>InfluxDB backup procedures</li> <li>Configuration backups</li> <li>Disaster recovery plan</li> </ul> <p>Next: Service Dockerfiles &amp; Design</p>"},{"location":"maintainer/server-admin/","title":"Server Administration","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers.</p>"},{"location":"maintainer/server-admin/#computing-servers-overview","title":"Computing Servers Overview","text":"<p>All computing servers (GPU servers and Threadripper) share a similar configuration:</p> <ul> <li>Ubuntu [version to be added]</li> <li>SSSD for LDAP authentication</li> <li>NFS mount for NAS</li> <li>Centralized user management</li> </ul>"},{"location":"maintainer/server-admin/#sssd-configuration","title":"SSSD Configuration","text":"<p>SSSD (System Security Services Daemon) connects the servers to the central LDAP server for authentication.</p>"},{"location":"maintainer/server-admin/#configuration-file","title":"Configuration File","text":"<p>Location: <code>/etc/sssd/sssd.conf</code></p> <p>[Content to be added: Actual configuration]</p> <pre><code>[sssd]\nservices = nss, pam\nconfig_file_version = 2\ndomains = lab.example.com\n\n[domain/lab.example.com]\nid_provider = ldap\nauth_provider = ldap\nldap_uri = ldap://core.example.com\nldap_search_base = dc=lab,dc=example,dc=com\n...\n</code></pre>"},{"location":"maintainer/server-admin/#troubleshooting-sssd","title":"Troubleshooting SSSD","text":"<pre><code># Check SSSD status\nsudo systemctl status sssd\n\n# Restart SSSD\nsudo systemctl restart sssd\n\n# Clear SSSD cache\nsudo sss_cache -E\n\n# Test user lookup\ngetent passwd username\n\n# Debug mode\nsudo sssd -i -d 9\n</code></pre>"},{"location":"maintainer/server-admin/#nfs-configuration","title":"NFS Configuration","text":"<p>The NAS is mounted via NFS on all computing servers.</p>"},{"location":"maintainer/server-admin/#mount-configuration","title":"Mount Configuration","text":"<p>Location: <code>/etc/fstab</code></p> <p>[Content to be added: Actual mount configuration]</p> <pre><code>nas.example.com:/volume1/homes  /nas/homes  nfs  defaults  0  0\nnas.example.com:/volume1/data   /data       nfs  ro,defaults  0  0\n</code></pre>"},{"location":"maintainer/server-admin/#nfs-troubleshooting","title":"NFS Troubleshooting","text":"<pre><code># Check mounts\nmount | grep nfs\n\n# Remount\nsudo mount -a\n\n# Check NFS server connectivity\nshowmount -e nas.example.com\n</code></pre>"},{"location":"maintainer/server-admin/#user-management","title":"User Management","text":""},{"location":"maintainer/server-admin/#adding-a-new-user","title":"Adding a New User","text":"<p>Users are managed centrally in LDAP:</p> <ol> <li>Use LDAP Account Manager web interface</li> <li>Create user with appropriate groups</li> <li>Set initial password</li> <li>User will appear on all servers automatically via SSSD</li> </ol> <p>[Content to be added: Detailed steps]</p>"},{"location":"maintainer/server-admin/#user-home-directories","title":"User Home Directories","text":"<p>Each user gets:</p> <ol> <li>Local home: Created automatically on first login</li> <li>NAS home: Must be created manually on NAS</li> </ol> <p>[Content to be added: Script or procedure for creating NAS homes]</p>"},{"location":"maintainer/server-admin/#disabling-a-user","title":"Disabling a User","text":"<p>[Content to be added: Procedure for disabling users]</p>"},{"location":"maintainer/server-admin/#sudo-access-management","title":"Sudo Access Management","text":""},{"location":"maintainer/server-admin/#gpu-servers","title":"GPU Servers","text":"<p>GPU servers have a dedicated sudo account that students can access:</p> <p>[Content to be added]</p> <ul> <li>How the sudo account is configured</li> <li>How users access it</li> <li>Limitations and restrictions</li> </ul>"},{"location":"maintainer/server-admin/#threadripper","title":"Threadripper","text":"<p>No sudo access for regular users. Rootless Podman is used instead.</p>"},{"location":"maintainer/server-admin/#gpu-management","title":"GPU Management","text":""},{"location":"maintainer/server-admin/#nvidia-driver-installation","title":"NVIDIA Driver Installation","text":"<p>[Content to be added]</p> <ul> <li>Driver version</li> <li>CUDA version</li> <li>Installation procedure</li> <li>Updating drivers</li> </ul>"},{"location":"maintainer/server-admin/#monitoring-gpu-usage","title":"Monitoring GPU Usage","text":"<pre><code># Install monitoring tools\nsudo apt install nvtop\n\n# Real-time monitoring\nnvidia-smi -l 1\n</code></pre>"},{"location":"maintainer/server-admin/#system-updates","title":"System Updates","text":""},{"location":"maintainer/server-admin/#regular-updates","title":"Regular Updates","text":"<p>[Content to be added]</p> <ul> <li>Update schedule</li> <li>Testing procedure</li> <li>Notification to users</li> </ul>"},{"location":"maintainer/server-admin/#kernel-updates","title":"Kernel Updates","text":"<p>[Content to be added]</p> <ul> <li>Special considerations for NVIDIA drivers</li> <li>Testing before applying</li> </ul>"},{"location":"maintainer/server-admin/#storage-management","title":"Storage Management","text":""},{"location":"maintainer/server-admin/#disk-quotas","title":"Disk Quotas","text":"<p>[Content to be added]</p> <ul> <li>Are quotas enabled?</li> <li>Quota limits</li> <li>Enforcing quotas</li> </ul>"},{"location":"maintainer/server-admin/#cleaning-up","title":"Cleaning Up","text":"<p>[Content to be added]</p> <ul> <li>Finding large files</li> <li>Cleaning temp directories</li> <li>User notification procedures</li> </ul>"},{"location":"maintainer/server-admin/#network-configuration","title":"Network Configuration","text":"<p>[Content to be added]</p> <ul> <li>IP address assignments</li> <li>DNS configuration</li> <li>Firewall rules (if any)</li> </ul>"},{"location":"maintainer/server-admin/#security","title":"Security","text":""},{"location":"maintainer/server-admin/#ssh-configuration","title":"SSH Configuration","text":"<p>[Content to be added]</p> <ul> <li>Key-only authentication</li> <li>Port configuration</li> <li>Fail2ban or similar</li> </ul>"},{"location":"maintainer/server-admin/#firewall","title":"Firewall","text":"<p>[Content to be added]</p> <ul> <li>iptables/ufw configuration</li> <li>Allowed ports</li> </ul>"},{"location":"maintainer/server-admin/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>[Content to be added]</p> <ul> <li>Log locations</li> <li>Monitoring tools</li> <li>Alerting setup</li> </ul>"},{"location":"maintainer/server-admin/#common-administrative-tasks","title":"Common Administrative Tasks","text":""},{"location":"maintainer/server-admin/#restarting-a-server","title":"Restarting a Server","text":"<p>[Content to be added]</p> <ul> <li>Pre-restart checklist</li> <li>Notifying users</li> <li>Post-restart verification</li> </ul>"},{"location":"maintainer/server-admin/#adding-new-software","title":"Adding New Software","text":"<p>[Content to be added]</p> <ul> <li>System-wide installations</li> <li>Managing conflicts</li> </ul>"},{"location":"maintainer/server-admin/#performance-tuning","title":"Performance Tuning","text":"<p>[Content to be added]</p> <ul> <li>CPU governor settings</li> <li>Network tuning</li> <li>Disk I/O optimization</li> </ul> <p>Next: Weather Sensor Systems</p>"},{"location":"maintainer/storage/","title":"Storage Infrastructure","text":"<p>Maintainer Documentation</p> <p>This section is intended for system administrators and future maintainers.</p>"},{"location":"maintainer/storage/#overview","title":"Overview","text":"<p>The lab storage infrastructure consists of two Synology NAS systems with different roles.</p>"},{"location":"maintainer/storage/#current-nas-80tb","title":"Current NAS (80TB)","text":"<p>Model: [To be added] Capacity: 80TB Role: User homes and shared data</p>"},{"location":"maintainer/storage/#storage-pool-configuration","title":"Storage Pool Configuration","text":"<p>[Content to be added]</p> <ul> <li>RAID configuration</li> <li>Drive configuration</li> <li>Performance characteristics</li> </ul>"},{"location":"maintainer/storage/#shared-folders","title":"Shared Folders","text":""},{"location":"maintainer/storage/#homes","title":"<code>/homes</code>","text":"<p>Purpose: User home directories</p> <p>[Content to be added]</p> <ul> <li>Quota settings</li> <li>Permissions</li> <li>Backup policy</li> <li>Access controls</li> </ul>"},{"location":"maintainer/storage/#data","title":"<code>/data</code>","text":"<p>Purpose: Shared research datasets</p> <p>[Content to be added]</p> <ul> <li>Organization structure</li> <li>Access permissions (read-only for most users)</li> <li>Dataset inventory</li> <li>Update procedures</li> </ul> <p>Current Datasets:</p> <ul> <li>ERA5 reanalysis data</li> <li>IMERG precipitation data</li> <li>Weather radar data</li> <li>Satellite observations</li> <li>Rain gauge measurements</li> <li>[Add more as applicable]</li> </ul>"},{"location":"maintainer/storage/#nfs-configuration","title":"NFS Configuration","text":"<p>[Content to be added]</p> <ul> <li>NFS version</li> <li>Export configuration</li> <li>Client permissions</li> <li>Performance tuning</li> </ul> <pre><code># Example /etc/exports on NAS\n/volume1/homes    *(rw,sync,no_subtree_check,root_squash)\n/volume1/data     *(ro,sync,no_subtree_check)\n</code></pre>"},{"location":"maintainer/storage/#backup-strategy","title":"Backup Strategy","text":"<p>[Content to be added]</p> <ul> <li>What is backed up</li> <li>Backup schedule</li> <li>Backup destination</li> <li>Retention policy</li> <li>Restore procedures</li> </ul>"},{"location":"maintainer/storage/#future-nas-18-bay","title":"Future NAS (18-bay)","text":"<p>Model: [To be added] Capacity: [To be added] Role: Primary data storage Status: Not yet configured</p>"},{"location":"maintainer/storage/#migration-plan","title":"Migration Plan","text":"<p>[Content to be added]</p> <p>The goal is to split storage by function:</p> <ul> <li>Old NAS (80TB): User homes</li> <li>New NAS (18-bay): Research datasets</li> </ul>"},{"location":"maintainer/storage/#migration-steps","title":"Migration Steps","text":"<p>[Content to be added]</p> <ol> <li>Physical setup and RAID configuration</li> <li>Data transfer planning</li> <li>Service interruption scheduling</li> <li>Data migration</li> <li>NFS reconfiguration on compute servers</li> <li>Testing and verification</li> <li>Old data cleanup</li> </ol>"},{"location":"maintainer/storage/#considerations","title":"Considerations","text":"<p>[Content to be added]</p> <ul> <li>Downtime requirements</li> <li>Data integrity verification</li> <li>User notification</li> <li>Rollback plan</li> </ul>"},{"location":"maintainer/storage/#synology-administration","title":"Synology Administration","text":""},{"location":"maintainer/storage/#dsm-access","title":"DSM Access","text":"<p>[Content to be added]</p> <ul> <li>Web interface URL</li> <li>Admin credentials storage</li> <li>2FA setup</li> </ul>"},{"location":"maintainer/storage/#storage-manager","title":"Storage Manager","text":"<p>[Content to be added]</p> <ul> <li>Monitoring disk health</li> <li>RAID scrubbing schedule</li> <li>Hot spare configuration</li> </ul>"},{"location":"maintainer/storage/#package-management","title":"Package Management","text":"<p>[Content to be added]</p> <ul> <li>Installed packages</li> <li>NFS server configuration</li> <li>LDAP client configuration (if used)</li> </ul>"},{"location":"maintainer/storage/#dataset-management","title":"Dataset Management","text":""},{"location":"maintainer/storage/#adding-new-datasets","title":"Adding New Datasets","text":"<p>[Content to be added]</p> <p>Procedures for adding new data sources:</p> <ol> <li>Determine storage location</li> <li>Create directory structure</li> <li>Set permissions</li> <li>Update documentation</li> <li>Notify users</li> </ol>"},{"location":"maintainer/storage/#data-update-procedures","title":"Data Update Procedures","text":"<p>[Content to be added]</p> <p>For regularly updated datasets (ERA5, IMERG, etc.):</p> <ul> <li>Update frequency</li> <li>Automated update scripts (if any)</li> <li>Verification procedures</li> <li>Version management</li> </ul>"},{"location":"maintainer/storage/#data-retention","title":"Data Retention","text":"<p>[Content to be added]</p> <ul> <li>Policies for old data</li> <li>Archival procedures</li> <li>Deletion procedures</li> </ul>"},{"location":"maintainer/storage/#monitoring","title":"Monitoring","text":""},{"location":"maintainer/storage/#disk-health","title":"Disk Health","text":"<p>[Content to be added]</p> <pre><code># Example SMART monitoring\nsmartctl -a /dev/sdX\n</code></pre>"},{"location":"maintainer/storage/#capacity-management","title":"Capacity Management","text":"<p>[Content to be added]</p> <ul> <li>Monitoring disk usage</li> <li>Alert thresholds</li> <li>Cleanup procedures</li> </ul>"},{"location":"maintainer/storage/#performance-monitoring","title":"Performance Monitoring","text":"<p>[Content to be added]</p> <ul> <li>I/O statistics</li> <li>Network throughput</li> <li>Identifying bottlenecks</li> </ul>"},{"location":"maintainer/storage/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":""},{"location":"maintainer/storage/#backup-infrastructure","title":"Backup Infrastructure","text":"<p>[Content to be added]</p> <ul> <li>Backup destination</li> <li>Backup software/method</li> <li>Schedule</li> <li>What is backed up</li> </ul>"},{"location":"maintainer/storage/#restore-procedures","title":"Restore Procedures","text":"<p>[Content to be added]</p> <ul> <li>File-level restore</li> <li>Full system restore</li> <li>Testing restore procedures</li> </ul>"},{"location":"maintainer/storage/#disaster-recovery-plan","title":"Disaster Recovery Plan","text":"<p>[Content to be added]</p> <ul> <li>What to do if NAS fails</li> <li>Data redundancy</li> <li>Recovery time objectives</li> <li>Recovery point objectives</li> </ul>"},{"location":"maintainer/storage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"maintainer/storage/#common-issues","title":"Common Issues","text":"<p>[Content to be added]</p>"},{"location":"maintainer/storage/#disk-failure","title":"Disk Failure","text":"<p>[Content to be added]</p>"},{"location":"maintainer/storage/#nfs-mount-issues","title":"NFS Mount Issues","text":"<p>[Content to be added]</p>"},{"location":"maintainer/storage/#performance-problems","title":"Performance Problems","text":"<p>[Content to be added]</p>"},{"location":"maintainer/storage/#access-permission-issues","title":"Access Permission Issues","text":"<p>[Content to be added]</p>"},{"location":"maintainer/storage/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"maintainer/storage/#regular-maintenance","title":"Regular Maintenance","text":"<p>[Content to be added]</p> <ul> <li>RAID scrubbing</li> <li>Firmware updates</li> <li>Backup verification</li> <li>Disk health checks</li> </ul>"},{"location":"maintainer/storage/#capacity-planning","title":"Capacity Planning","text":"<p>[Content to be added]</p> <ul> <li>Growth rate analysis</li> <li>Forecasting capacity needs</li> <li>Expansion planning</li> </ul> <p>Next: Future Roadmap &amp; Maintenance</p>"},{"location":"reference/faq/","title":"Frequently Asked Questions","text":""},{"location":"reference/faq/#account-and-access","title":"Account and Access","text":""},{"location":"reference/faq/#how-do-i-get-an-account","title":"How do I get an account?","text":"<p>[Content to be added: Specific process for your lab]</p> <p>Contact the lab administrator or your advisor to request an account.</p>"},{"location":"reference/faq/#i-forgot-my-password-how-do-i-reset-it","title":"I forgot my password. How do I reset it?","text":"<p>[Content to be added: Password reset procedure]</p>"},{"location":"reference/faq/#my-ssh-key-isnt-working-what-should-i-check","title":"My SSH key isn't working. What should I check?","text":"<ol> <li>Verify you uploaded the public key (<code>.pub</code> file), not the private key</li> <li>Check that the key is properly uploaded in LDAP Account Manager</li> <li>Ensure your local SSH config points to the correct private key</li> <li>Check file permissions: <code>~/.ssh/id_ed25519</code> should be 600</li> </ol>"},{"location":"reference/faq/#why-do-i-have-two-home-directories","title":"Why do I have two home directories?","text":"<p>For performance and accessibility: - Local home (<code>/home/username</code>): Fast local storage on each server - NAS home (<code>/nas/homes/username</code>): Shared across all servers via network</p> <p>Use local home for temporary work, NAS home for important files you want to keep.</p>"},{"location":"reference/faq/#server-usage","title":"Server Usage","text":""},{"location":"reference/faq/#which-server-should-i-use-for-my-task","title":"Which server should I use for my task?","text":"<ul> <li>Quick experiments, interactive work: GPU servers (i7, i9, or 5950)</li> <li>Data processing, many CPU cores: Threadripper</li> <li>Long production runs: Taiwan HPC</li> </ul>"},{"location":"reference/faq/#can-i-run-long-jobs-on-gpu-servers","title":"Can I run long jobs on GPU servers?","text":"<p>Yes, but use <code>screen</code> or <code>tmux</code> so your job continues if you disconnect.</p>"},{"location":"reference/faq/#how-do-i-check-if-someone-is-using-the-gpu","title":"How do I check if someone is using the GPU?","text":"<pre><code>nvidia-smi\n</code></pre> <p>Look at the \"Processes\" section to see what's running.</p>"},{"location":"reference/faq/#the-server-is-slow-what-should-i-do","title":"The server is slow. What should I do?","text":"<p>Check resource usage: <pre><code>htop          # CPU and memory usage\nnvidia-smi    # GPU usage\ndf -h         # Disk space\n</code></pre></p> <p>If someone else is using all resources, wait or use another server.</p>"},{"location":"reference/faq/#containers-and-podman","title":"Containers and Podman","text":""},{"location":"reference/faq/#whats-the-difference-between-docker-and-podman","title":"What's the difference between Docker and Podman?","text":"<p>They're very similar! Podman can run rootless (without sudo) and commands are nearly identical. Just replace <code>docker</code> with <code>podman</code>.</p>"},{"location":"reference/faq/#why-do-we-use-containers","title":"Why do we use containers?","text":"<ul> <li>Reproducibility: Your environment is the same everywhere</li> <li>Portability: Same container runs on lab servers and HPC</li> <li>Isolation: Your work doesn't conflict with others'</li> </ul>"},{"location":"reference/faq/#do-i-have-to-use-containers","title":"Do I have to use containers?","text":"<ul> <li>GPU servers: No, but recommended</li> <li>Threadripper: Yes, because you don't have sudo access</li> <li>HPC: Usually yes</li> </ul>"},{"location":"reference/faq/#where-can-i-find-base-images","title":"Where can I find base images?","text":"<p>Check our Harbor registry: [URL to be added]</p>"},{"location":"reference/faq/#my-container-cant-access-my-files-whats-wrong","title":"My container can't access my files. What's wrong?","text":"<p>You need to mount directories with the <code>-v</code> flag: <pre><code>podman run -v /nas/homes/username:/workspace:Z ...\n</code></pre></p> <p>Don't forget the <code>:Z</code> flag!</p>"},{"location":"reference/faq/#data-and-storage","title":"Data and Storage","text":""},{"location":"reference/faq/#where-should-i-store-my-data","title":"Where should I store my data?","text":"<ul> <li>Raw datasets: Don't copy! Use from <code>/data</code> directly</li> <li>Your code and results: NAS home (<code>/nas/homes/username</code>)</li> <li>Temporary processing files: Local home</li> </ul>"},{"location":"reference/faq/#im-running-out-of-space-what-should-i-do","title":"I'm running out of space. What should I do?","text":"<p>Check your usage: <pre><code>du -sh ~\ndu -sh /nas/homes/username\n</code></pre></p> <p>Clean up: - Remove old temporary files - Delete unused container images: <code>podman image prune</code> - Compress old results</p>"},{"location":"reference/faq/#how-do-i-access-the-shared-datasets-era5-imerg","title":"How do I access the shared datasets (ERA5, IMERG)?","text":"<p>They're in <code>/data</code>: <pre><code>ls /data/ERA5\nls /data/IMERG\n</code></pre></p> <p>Reference them directly in your scripts - don't copy!</p>"},{"location":"reference/faq/#hpc","title":"HPC","text":""},{"location":"reference/faq/#how-do-i-get-access-to-taiwan-hpc","title":"How do I get access to Taiwan HPC?","text":"<p>[Content to be added: Specific application process]</p>"},{"location":"reference/faq/#can-i-use-my-lab-containers-on-hpc","title":"Can I use my lab containers on HPC?","text":"<p>Yes! Convert them to Singularity/Apptainer format. See Preparing for HPC.</p>"},{"location":"reference/faq/#how-long-does-my-hpc-job-take-to-start","title":"How long does my HPC job take to start?","text":"<p>It depends on the queue and requested resources. Could be minutes to hours. Check with <code>squeue</code>.</p>"},{"location":"reference/faq/#linux-and-ssh","title":"Linux and SSH","text":""},{"location":"reference/faq/#im-new-to-linux-where-should-i-start","title":"I'm new to Linux. Where should I start?","text":"<p>Start with these sections: 1. Why Linux? 2. Linux Command Line Basics 3. Using VSCode for a more familiar interface</p>"},{"location":"reference/faq/#how-do-i-transfer-files-tofrom-the-server","title":"How do I transfer files to/from the server?","text":"<ul> <li>With VSCode: Drag and drop in the file explorer</li> <li>Command line: Use <code>scp</code> or <code>rsync</code></li> <li>Large datasets: Use <code>rsync</code> for resumable transfers</li> </ul>"},{"location":"reference/faq/#whats-the-difference-between-and-homeusername","title":"What's the difference between <code>~</code> and <code>/home/username</code>?","text":"<p>They're the same! <code>~</code> is a shortcut to your home directory.</p>"},{"location":"reference/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/faq/#permission-denied-error","title":"\"Permission denied\" error","text":"<p>Check: 1. File permissions: <code>ls -l filename</code> 2. If it's a script, make it executable: <code>chmod +x script.sh</code> 3. If SSH: Check your SSH key setup</p>"},{"location":"reference/faq/#no-space-left-on-device","title":"\"No space left on device\"","text":"<p>You've run out of disk space: <pre><code>df -h          # Check disk usage\ndu -sh ~/*     # Find large directories\n</code></pre></p> <p>Clean up unnecessary files or contact the administrator.</p>"},{"location":"reference/faq/#cannot-connect-to-server","title":"\"Cannot connect to server\"","text":"<ol> <li>Check your internet connection</li> <li>Verify the server hostname/IP is correct</li> <li>Check if a VPN is required [if applicable]</li> <li>Try pinging the server: <code>ping hostname</code></li> </ol>"},{"location":"reference/faq/#my-job-is-killed-unexpectedly","title":"My job is killed unexpectedly","text":"<p>Possible causes: - Out of memory: Check logs and request more memory - Out of disk space: Clean up temporary files - Time limit exceeded (on HPC): Request more time</p>"},{"location":"reference/faq/#getting-more-help","title":"Getting More Help","text":""},{"location":"reference/faq/#where-can-i-find-more-information","title":"Where can I find more information?","text":"<ul> <li>This documentation!</li> <li>Ask senior lab members</li> <li>Check the External Resources page</li> </ul>"},{"location":"reference/faq/#who-should-i-contact-for-help","title":"Who should I contact for help?","text":"<ul> <li>Account issues: [Contact to be added]</li> <li>Hardware problems: [Contact to be added]</li> <li>HPC questions: [Contact to be added]</li> <li>Research questions: Your advisor or senior lab members</li> </ul>"},{"location":"reference/faq/#how-do-i-report-a-problem","title":"How do I report a problem?","text":"<p>[Content to be added: Issue reporting procedure]</p>"},{"location":"reference/faq/#can-i-request-new-software-or-hardware","title":"Can I request new software or hardware?","text":"<p>[Content to be added: Request procedure]</p>"},{"location":"reference/glossary/","title":"Glossary","text":""},{"location":"reference/glossary/#infrastructure-terms","title":"Infrastructure Terms","text":"<p>LDAP (Lightweight Directory Access Protocol) : A protocol for accessing and managing directory information services. In our lab, LDAP provides centralized user authentication across all servers.</p> <p>NAS (Network Attached Storage) : A file-level storage device connected to a network. Our lab uses Synology NAS systems for shared data and user home directories.</p> <p>NFS (Network File System) : A distributed file system protocol that allows file access over a network. Used to mount NAS directories on computing servers.</p> <p>SSSD (System Security Services Daemon) : Software that allows Linux systems to authenticate against remote identity providers like LDAP.</p> <p>Traefik : A modern reverse proxy and load balancer that routes HTTP/HTTPS traffic to different services.</p>"},{"location":"reference/glossary/#container-terms","title":"Container Terms","text":"<p>Container : A lightweight, standalone package that includes an application and all its dependencies.</p> <p>Image : A template used to create containers. Think of it as a snapshot of a filesystem.</p> <p>Docker : The most popular container platform. Requires root/sudo privileges.</p> <p>Podman : A Docker-compatible container tool that can run without root privileges (rootless).</p> <p>Rootless : Running containers without requiring administrator (root) privileges.</p> <p>Harbor : An open-source container registry. Our lab runs a private Harbor instance.</p> <p>Registry : A storage and distribution system for container images.</p> <p>Dockerfile : A text file with instructions for building a container image.</p> <p>Volume : Persistent storage for containers that survives container restarts/deletions.</p>"},{"location":"reference/glossary/#hpc-terms","title":"HPC Terms","text":"<p>HPC (High-Performance Computing) : Large-scale computing systems designed for intensive computational tasks.</p> <p>SLURM : Simple Linux Utility for Resource Management - a job scheduler used on HPC systems.</p> <p>Job : A computational task submitted to an HPC scheduler.</p> <p>Queue/Partition : A group of nodes with specific characteristics (GPUs, memory, etc.) on an HPC system.</p> <p>Node : A single computer in an HPC cluster.</p> <p>Module : A system for managing different software versions on HPC systems.</p> <p>Singularity/Apptainer : A container platform designed for HPC environments (Apptainer is the new name for Singularity).</p>"},{"location":"reference/glossary/#authentication-terms","title":"Authentication Terms","text":"<p>SSH (Secure Shell) : A protocol for secure remote login and command execution.</p> <p>SSH Key : A cryptographic key pair (public and private) used for authentication.</p> <p>Public Key : The shareable part of an SSH key pair, uploaded to servers.</p> <p>Private Key : The secret part of an SSH key pair, never shared.</p> <p>LDAP Account Manager (LAM) : A web-based interface for managing LDAP accounts and SSH keys.</p>"},{"location":"reference/glossary/#networking-terms","title":"Networking Terms","text":"<p>Port : A logical communication endpoint. Web servers typically use port 80 (HTTP) or 443 (HTTPS).</p> <p>Reverse Proxy : A server that forwards requests to other servers. Traefik is our reverse proxy.</p> <p>MQTT : A lightweight messaging protocol, used for our sensor data.</p> <p>EMQX : An MQTT broker (message server) used for collecting sensor data.</p>"},{"location":"reference/glossary/#data-terms","title":"Data Terms","text":"<p>ERA5 : A global atmospheric reanalysis dataset produced by ECMWF.</p> <p>IMERG : Integrated Multi-satellitE Retrievals for GPM - a NASA precipitation dataset.</p> <p>Time-Series Database : A database optimized for time-stamped data. InfluxDB is our time-series database.</p> <p>InfluxDB : An open-source time-series database used for storing sensor data.</p>"},{"location":"reference/glossary/#linux-terms","title":"Linux Terms","text":"<p>Terminal/Shell : A command-line interface for interacting with Linux.</p> <p>Bash : The most common Linux shell.</p> <p>Home Directory : A user's personal directory, usually <code>/home/username</code>.</p> <p>Root : The administrator account with full system privileges.</p> <p>Sudo : A command that allows running other commands with administrator privileges.</p> <p>Path : The location of a file or directory in the filesystem.</p> <p>Environment Variable : A named value that can affect how programs run.</p>"},{"location":"reference/glossary/#gpu-terms","title":"GPU Terms","text":"<p>GPU (Graphics Processing Unit) : Originally for graphics, now widely used for parallel computing and AI.</p> <p>CUDA : NVIDIA's parallel computing platform and programming model.</p> <p>nvidia-smi : NVIDIA System Management Interface - a tool for monitoring GPU usage.</p>"},{"location":"reference/glossary/#sensor-terms","title":"Sensor Terms","text":"<p>MQTT Topic : A hierarchical namespace for MQTT messages, like <code>lab/weather/sensor1/temperature</code>.</p> <p>Broker : A server that receives and forwards MQTT messages. EMQX is our broker.</p> <p>Publish/Subscribe : A messaging pattern where senders (publishers) send messages to topics, and receivers (subscribers) receive them.</p>"},{"location":"reference/quick-ref/","title":"Quick Reference","text":""},{"location":"reference/quick-ref/#ssh-connection","title":"SSH Connection","text":"<pre><code># Connect to servers (using SSH config)\nssh gpu1\nssh gpu2\nssh gpu3\nssh threadripper\n\n# Generate SSH key\nssh-keygen -t ed25519 -C \"your.email@example.com\"\n\n# Copy SSH key to clipboard (to upload to LAM)\ncat ~/.ssh/id_ed25519.pub\n</code></pre>"},{"location":"reference/quick-ref/#essential-linux-commands","title":"Essential Linux Commands","text":"<pre><code># Navigation\npwd                          # Show current directory\nls -lh                      # List files with details\ncd directory_name           # Change directory\ncd ~                        # Go to home\ncd ..                       # Go up one level\n\n# File operations\ncp source dest              # Copy file\nmv source dest              # Move/rename file\nrm file                     # Delete file\nmkdir directory             # Create directory\n\n# Viewing files\ncat file.txt                # Display file\nless file.txt               # View file (q to quit)\nhead -n 20 file.txt         # First 20 lines\ntail -f logfile.txt         # Follow file updates\n\n# Searching\ngrep \"text\" file.txt        # Search in file\nfind . -name \"*.py\"         # Find files by name\n\n# Disk usage\ndf -h                       # Disk space\ndu -sh directory/           # Directory size\n\n# Processes\nhtop                        # Monitor processes\nnvidia-smi                  # GPU status\n</code></pre>"},{"location":"reference/quick-ref/#podman-commands","title":"Podman Commands","text":"<pre><code># Pull images\npodman pull harbor.example.com/base/python:latest\n\n# Run container\npodman run -it ubuntu:latest bash\npodman run -d --name mycontainer ubuntu:latest\n\n# With volume mounts\npodman run -it \\\n  -v /nas/homes/username:/workspace:Z \\\n  -v /data:/data:Z \\\n  image:tag bash\n\n# Manage containers\npodman ps                   # List running containers\npodman ps -a               # List all containers\npodman stop container-name\npodman start container-name\npodman rm container-name\n\n# Manage images\npodman images              # List images\npodman rmi image-name      # Remove image\npodman image prune         # Clean up unused images\n\n# Execute in running container\npodman exec -it container-name bash\n\n# View logs\npodman logs container-name\npodman logs -f container-name    # Follow logs\n</code></pre>"},{"location":"reference/quick-ref/#gpu-monitoring","title":"GPU Monitoring","text":"<pre><code># One-time check\nnvidia-smi\n\n# Continuous monitoring\nwatch -n 1 nvidia-smi\n\n# Detailed info\nnvidia-smi -l 1            # Update every second\nnvidia-smi --query-gpu=utilization.gpu --format=csv -l 1\n</code></pre>"},{"location":"reference/quick-ref/#slurm-commands-hpc","title":"SLURM Commands (HPC)","text":"<pre><code># Submit job\nsbatch job_script.sh\n\n# Check queue\nsqueue                      # All jobs\nsqueue -u username          # Your jobs\n\n# Cancel job\nscancel job-id\n\n# Job info\nsinfo                       # Cluster info\nsacct                       # Job history\n</code></pre>"},{"location":"reference/quick-ref/#module-commands-hpc","title":"Module Commands (HPC)","text":"<pre><code># Available modules\nmodule avail\nmodule avail python\n\n# Load modules\nmodule load python/3.10\nmodule load cuda/11.8\n\n# List loaded\nmodule list\n\n# Unload\nmodule unload python/3.10\nmodule purge               # Unload all\n</code></pre>"},{"location":"reference/quick-ref/#data-locations","title":"Data Locations","text":"<pre><code># Your homes\n/home/username              # Local home (fast, not shared)\n/nas/homes/username         # NAS home (shared across servers)\n\n# Shared data\n/data/ERA5                  # ERA5 reanalysis\n/data/IMERG                 # GPM IMERG precipitation\n/data/radar                 # Radar data\n/data/satellite             # Satellite data\n/data/gauge                 # Gauge data\n</code></pre>"},{"location":"reference/quick-ref/#server-information","title":"Server Information","text":""},{"location":"reference/quick-ref/#gpu-servers","title":"GPU Servers","text":"Server Hostname GPU Purpose 1 [To be added] RTX 3080 Ti Quick experiments 2 [To be added] RTX 4090 Heavy computation 3 [To be added] RTX 3090 General GPU work <p>Access: Direct SSH, sudo available via dedicated account</p>"},{"location":"reference/quick-ref/#threadripper-server","title":"Threadripper Server","text":"Hostname CPU Purpose [To be added] Threadripper 7965 Data processing <p>Access: Rootless Podman only, no sudo</p>"},{"location":"reference/quick-ref/#common-file-paths","title":"Common File Paths","text":"<pre><code># SSH config\n~/.ssh/config\n\n# SSH keys\n~/.ssh/id_ed25519          # Private key\n~/.ssh/id_ed25519.pub      # Public key\n\n# Podman storage\n~/.local/share/containers/storage/\n\n# Bash config\n~/.bashrc\n~/.bash_profile\n</code></pre>"},{"location":"reference/quick-ref/#screentmux-for-long-jobs","title":"Screen/Tmux (For Long Jobs)","text":"<pre><code># Screen\nscreen -S session-name     # Create session\n# Ctrl+A then D             # Detach\nscreen -ls                 # List sessions\nscreen -r session-name     # Reattach\n\n# Tmux\ntmux new -s session-name   # Create session\n# Ctrl+B then D             # Detach\ntmux ls                    # List sessions\ntmux attach -t session-name # Reattach\n</code></pre>"},{"location":"reference/quick-ref/#file-permissions","title":"File Permissions","text":"<pre><code># Check permissions\nls -l file\n\n# Make executable\nchmod +x script.sh\n\n# Change permissions (owner, group, others)\nchmod 755 file             # rwxr-xr-x\nchmod 644 file             # rw-r--r--\n</code></pre>"},{"location":"reference/quick-ref/#harbor-registry","title":"Harbor Registry","text":"<pre><code># Login\npodman login harbor.example.com\n\n# Pull image\npodman pull harbor.example.com/library/image:tag\n\n# Tag image\npodman tag local-image:tag harbor.example.com/project/image:tag\n\n# Push image\npodman push harbor.example.com/project/image:tag\n</code></pre>"},{"location":"reference/quick-ref/#useful-aliases-add-to-bashrc","title":"Useful Aliases (Add to ~/.bashrc)","text":"<pre><code>alias ll='ls -lh'\nalias la='ls -lah'\nalias gpu='nvidia-smi'\nalias pods='podman ps'\nalias podsa='podman ps -a'\n</code></pre>"},{"location":"reference/quick-ref/#getting-help","title":"Getting Help","text":"<pre><code># Command help\nman command                # Manual page\ncommand --help            # Quick help\n</code></pre>"},{"location":"reference/quick-ref/#service-urls","title":"Service URLs","text":"<p>[Content to be added: Actual URLs]</p> <ul> <li>Harbor: <code>https://harbor.example.com</code></li> <li>LDAP Account Manager: <code>https://lam.example.com</code></li> <li>Web Portal: <code>https://portal.example.com</code></li> </ul>"},{"location":"reference/resources/","title":"External Resources","text":""},{"location":"reference/resources/#linux-basics","title":"Linux Basics","text":""},{"location":"reference/resources/#interactive-tutorials","title":"Interactive Tutorials","text":"<ul> <li>Linux Journey - Comprehensive interactive guide</li> <li>The Linux Command Line - Free online book</li> <li>Bash Scripting Tutorial - Learn bash scripting</li> </ul>"},{"location":"reference/resources/#quick-references","title":"Quick References","text":"<ul> <li>Linux Command Cheat Sheet</li> <li>Bash Cheat Sheet</li> </ul>"},{"location":"reference/resources/#ssh","title":"SSH","text":"<ul> <li>SSH Academy - Comprehensive SSH guide</li> <li>GitHub SSH Setup Guide</li> </ul>"},{"location":"reference/resources/#containers","title":"Containers","text":""},{"location":"reference/resources/#dockerpodman","title":"Docker/Podman","text":"<ul> <li>Docker Get Started - Most concepts apply to Podman too</li> <li>Podman Documentation</li> <li>Podman Tutorial</li> </ul>"},{"location":"reference/resources/#dockerfile-best-practices","title":"Dockerfile Best Practices","text":"<ul> <li>Dockerfile Best Practices</li> <li>Docker Tips and Tricks</li> </ul>"},{"location":"reference/resources/#singularityapptainer-hpc","title":"Singularity/Apptainer (HPC)","text":"<ul> <li>Apptainer Documentation</li> <li>Singularity Tutorial</li> </ul>"},{"location":"reference/resources/#python-for-scientific-computing","title":"Python for Scientific Computing","text":""},{"location":"reference/resources/#general-python","title":"General Python","text":"<ul> <li>Python Official Tutorial</li> <li>Real Python Tutorials</li> </ul>"},{"location":"reference/resources/#scientific-python-stack","title":"Scientific Python Stack","text":"<ul> <li>NumPy Documentation</li> <li>Pandas Documentation</li> <li>Matplotlib Tutorials</li> <li>xarray for multidimensional data</li> </ul>"},{"location":"reference/resources/#deep-learning","title":"Deep Learning","text":"<ul> <li>PyTorch Tutorials</li> <li>TensorFlow Tutorials</li> </ul>"},{"location":"reference/resources/#hpc-and-slurm","title":"HPC and SLURM","text":"<ul> <li>SLURM Documentation</li> <li>SLURM Quick Start</li> <li>HPC Carpentry - HPC Intro</li> </ul>"},{"location":"reference/resources/#vscode","title":"VSCode","text":"<ul> <li>VSCode Remote SSH</li> <li>VSCode Python</li> <li>VSCode Tips and Tricks</li> </ul>"},{"location":"reference/resources/#git-and-version-control","title":"Git and Version Control","text":"<ul> <li>Git Handbook</li> <li>Learn Git Branching - Interactive tutorial</li> <li>Oh My Git! - Game to learn Git</li> </ul>"},{"location":"reference/resources/#meteorological-data","title":"Meteorological Data","text":""},{"location":"reference/resources/#era5","title":"ERA5","text":"<ul> <li>ERA5 Documentation</li> <li>CDS Toolbox Tutorials</li> </ul>"},{"location":"reference/resources/#gpm-imerg","title":"GPM IMERG","text":"<ul> <li>IMERG Technical Documentation</li> <li>GES DISC User Guide</li> </ul>"},{"location":"reference/resources/#data-processing","title":"Data Processing","text":"<ul> <li>netCDF Documentation</li> <li>GDAL Documentation</li> <li>Rasterio Documentation</li> </ul>"},{"location":"reference/resources/#system-administration-for-maintainers","title":"System Administration (For Maintainers)","text":""},{"location":"reference/resources/#ldap","title":"LDAP","text":"<ul> <li>OpenLDAP Documentation</li> <li>LDAP for Rocket Scientists</li> </ul>"},{"location":"reference/resources/#nfs","title":"NFS","text":"<ul> <li>NFS HOWTO</li> </ul>"},{"location":"reference/resources/#dockercontainer-orchestration","title":"Docker/Container Orchestration","text":"<ul> <li>Docker Compose Documentation</li> <li>Traefik Documentation</li> </ul>"},{"location":"reference/resources/#monitoring","title":"Monitoring","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> </ul>"},{"location":"reference/resources/#online-courses","title":"Online Courses","text":""},{"location":"reference/resources/#linux-administration","title":"Linux Administration","text":"<ul> <li>Linux Foundation Training</li> <li>Udacity: Linux Command Line Basics</li> </ul>"},{"location":"reference/resources/#scientific-computing","title":"Scientific Computing","text":"<ul> <li>Software Carpentry - Great workshops on scientific computing</li> <li>Missing Semester of CS Education - Shell, Git, editors, etc.</li> </ul>"},{"location":"reference/resources/#python-for-data-science","title":"Python for Data Science","text":"<ul> <li>Python Data Science Handbook</li> <li>Kaggle Learn - Interactive tutorials</li> </ul>"},{"location":"reference/resources/#communities-and-forums","title":"Communities and Forums","text":"<ul> <li>Stack Overflow - Programming questions</li> <li>Unix &amp; Linux Stack Exchange - Linux questions</li> <li>r/linux4noobs - Beginner-friendly Linux community</li> <li>r/homelab - Self-hosting and infrastructure</li> </ul>"},{"location":"reference/resources/#books","title":"Books","text":""},{"location":"reference/resources/#linux","title":"Linux","text":"<ul> <li>\"The Linux Command Line\" by William Shotts (free online)</li> <li>\"How Linux Works\" by Brian Ward</li> </ul>"},{"location":"reference/resources/#python","title":"Python","text":"<ul> <li>\"Python for Data Analysis\" by Wes McKinney</li> <li>\"Automate the Boring Stuff with Python\" by Al Sweigart (free online)</li> </ul>"},{"location":"reference/resources/#hpc","title":"HPC","text":"<ul> <li>\"Introduction to High Performance Computing for Scientists and Engineers\" by Hager and Wellein</li> </ul>"},{"location":"reference/resources/#tools","title":"Tools","text":""},{"location":"reference/resources/#file-transfer","title":"File Transfer","text":"<ul> <li>FileZilla - GUI for SFTP</li> <li>WinSCP - Windows SFTP client</li> </ul>"},{"location":"reference/resources/#ssh-clients","title":"SSH Clients","text":"<ul> <li>PuTTY - Windows SSH client</li> <li>MobaXterm - Enhanced terminal for Windows</li> </ul>"},{"location":"reference/resources/#editors","title":"Editors","text":"<ul> <li>Vim Adventures - Learn Vim through a game</li> <li>Nano Guide</li> </ul>"},{"location":"reference/resources/#youtube-channels","title":"YouTube Channels","text":"<ul> <li>NetworkChuck - Networking and Linux</li> <li>LearnLinuxTV - Linux tutorials</li> <li>Corey Schafer - Python tutorials</li> </ul>"}]}